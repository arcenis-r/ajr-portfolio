<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Arcenis Rojas" />


<title>Opening the ML ‘Black Box’ with Shapley Values - A Tidy Approach</title>

<script src="site_libs/header-attrs-2.9/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">



<!DOCTYPE html>

<div class="navbar navbar-default  navbar-fixed-top" role="navigation" style="background-color:#000fff">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
          <span class="icon-bar"></span>
            <span class="icon-bar"></span>
              </button>
              <a class="navbar-brand" href="index.html" style="color:#FFF">Arcenis Rojas</a>
                </div>
                <div id="navbar" class="navbar-collapse collapse">
                  <ul class="nav navbar-nav">
                    
                    </ul>
                    <ul class="nav navbar-nav navbar-right">
                      <li>
                      <a href="https://github.com/arcenis-r">
                        <span class="fa fa-github fa-lg" style="color:#FFF"></span>
                          
                          </a>
                          </li>
                          <li>
                          <a href="https://linkedin.com/in/arcenisrojas">
                            <span class="fa fa-linkedin fa-lg" style="color:#FFF"></span>
                              
                              </a>
                              </li>
                              </ul>
                              </div><!--/.nav-collapse -->
                              </div><!--/.container -->
                              </div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Opening the ML ‘Black Box’ with Shapley Values - A Tidy Approach</h1>
<h4 class="author">Arcenis Rojas</h4>
<h4 class="date">8/29/2021</h4>

</div>

<div id="TOC">
<ul>
<li><a href="#introduction-motivation">Introduction / Motivation</a></li>
<li><a href="#getting-started">Getting Started</a></li>
<li><a href="#data-exploration">Data Exploration</a></li>
<li><a href="#modeling-prep">Modeling Prep</a></li>
<li><a href="#modeling">Modeling</a>
<ul>
<li><a href="#tuning-the-models">Tuning the Models</a></li>
<li><a href="#model-selection-and-fitting">Model Selection and Fitting</a></li>
<li><a href="#model-evaluation">Model Evaluation</a></li>
</ul></li>
<li><a href="#opening-the-black-box">Opening the “Black Box”</a>
<ul>
<li><a href="#generate-shap-values">Generate SHAP Values</a></li>
<li><a href="#plot-relationships-between-shap-and-the-training-data">Plot Relationships Between SHAP and the Training Data</a></li>
</ul></li>
<li><a href="#final-thoughts">Final Thoughts</a></li>
</ul>
</div>

<div id="introduction-motivation" class="section level1">
<h1>Introduction / Motivation</h1>
<p>Recently I worked on a project which required explanation of ML algorithms more precisely than with precision (I’ve heard you should always open with a bad joke). Being fairly new to the world of ML, I wasn’t aware of many ways to do that, but in my research I found <a href="https://dalex.drwhy.ai/">DALEX</a> developed by <a href="https://github.com/ModelOriented/">MI2DataLab</a>. I was impressed, surprised, and excited. I very quickly developed some code for my project and even built a <a href="https://modelstudio.drwhy.ai/">modelStudio</a> dashboard as a proof of concept. Some of the advantages of <a href="https://dalex.drwhy.ai/">DALEX</a> are that it…</p>
<ul>
<li>is model agnostic with comparable results across models</li>
<li>has an easy, consistent interface</li>
<li>produces easily interpretable visualizations</li>
<li>can generates HTML widgets/pages through modelStudio</li>
<li>provides Various ways to look at contributions of each observation to model predictions</li>
</ul>
<p>Upon presenting my proof of concept, though, I learned about some other project requirements that highlighted two disadvantages of <a href="https://dalex.drwhy.ai/">DALEX</a>. The R package does not…</p>
<ul>
<li>run in parallel</li>
<li>provide SHAP values</li>
<li>work natively (or easily) with <a href="https://www.tidymodels.org/">Tidymodel</a> objects</li>
</ul>
<p>These disadvantages were enough to have me go back to the drawing board. I wondered if there were other ways to get the same types of visualizations and model break-downs through or from other R packages. I found…</p>
<ul>
<li><a href="https://bgreenwell.github.io/fastshap/articles/fastshap.html">fastshap</a> for computing Shapley values</li>
<li><a href="https://bgreenwell.github.io/pdp/articles/pdp.html">pdp</a> for generating partial dependence plots</li>
<li><a href="https://koalaverse.github.io/vip/articles/vip.html">vip</a> for generating variable importance using different methods</li>
<li><a href="https://pbiecek.github.io/breakDown/">breakDown</a> for explaining variable contributions to individual predictions</li>
</ul>
<p>Since I was using Shapley values as a basis on which to explain everything I used only <a href="https://bgreenwell.github.io/fastshap/articles/fastshap.html">fastshap</a> and <a href="https://bgreenwell.github.io/pdp/articles/pdp.html">pdp</a>, but found that <a href="https://koalaverse.github.io/vip/articles/vip.html">vip</a> would work well if I wanted to use another method for computing variable importance like permutation. I found it a bit challenging to use <a href="https://pbiecek.github.io/breakDown/">breakDown</a> with <a href="https://www.tidymodels.org/">Tidymodel</a> objects, otherwise, it was pretty easy to work with.</p>
<p>I’m going to demonstrate how I used these packages to “open the black box” of ML algorithms. In the example below I’ll show how I did it using an XG Boost and a linear model algorithm since ‘lm’ is very standard and XG Boost can present some challenging data formatting requirements. I’ll be using the <a href="https://modeldata.tidymodels.org/reference/ames.html">Ames Housing Data</a> included in the <a href="https://modeldata.tidymodels.org/index.html">modeldata</a> package. I’m using this version rather than that from the <a href="https://cran.r-project.org/web/packages/AmesHousing/AmesHousing.pdf">AmesHousing package</a> because the good folks at <a href="https://www.rstudio.com/">RStudio</a> who work on <a href="https://www.tidymodels.org/">Tidymodels</a> did a great job of cleaning up the data a bit (thank you!) in their version and I didn’t want to spend a lot of time doing that for this demo. Also, I chose this data set because it has some things in common with the data that I used in the aforementioned project that prompted this work such as having mixed data types (discrete and numeric) in the explanatory variables, a large enough number of observations for training (and tuning) and testing a model, and some problems with multicollinearity (or redundancy) in the explanatory variables. As a quick aside, I’m also very grateful to the folks that work on the <a href="https://www.tidyverse.org/">Tidyverse</a> of packages; I use these in nearly every R session.</p>
</div>
<div id="getting-started" class="section level1">
<h1>Getting Started</h1>
<p>Prior to diving into the data, first I’ll ensure to have all required packages.</p>
<pre class="r"><code># Clear the workspace
rm(list = ls())

# Store a vector of packages names to install and load
pkg_list &lt;- c(
  &quot;tidyverse&quot;, &quot;tidymodels&quot;, &quot;magrittr&quot;, &quot;janitor&quot;, &quot;car&quot;, &quot;vip&quot;, &quot;fastshap&quot;, 
  &quot;pdp&quot;, &quot;corrr&quot;, &quot;xgboost&quot;, &quot;doParallel&quot;, &quot;future&quot;, &quot;furrr&quot;
)

# Install any packages that are not yet installed
invisible(
  lapply(
    pkg_list, 
    function(p) {
      if (!p %in% installed.packages()[, &quot;Package&quot;]) {
        install.packages(p, dependencies = TRUE, quiet = TRUE)
      }
    }
  )
)

# Also install the &#39;recipeselectors&#39; package from GitHub
if (!&quot;recipeselectors&quot; %in% installed.packages()[, &quot;Package&quot;]) {
  if (!&quot;devtools&quot; %in% installed.packages()[, &quot;Package&quot;]) {
    invisible(install.packages(devtools, dependencies = TRUE, quiet = TRUE))
  }
  
  invisible(devtools::install_github(&quot;stevenpawley/recipeselectors&quot;))
}

# Load packages that will be used throughout the code
library(fastshap, quietly = TRUE)
library(tidyverse, quietly = TRUE)</code></pre>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──</code></pre>
<pre><code>## ✓ ggplot2 3.3.4     ✓ purrr   0.3.4
## ✓ tibble  3.1.2     ✓ dplyr   1.0.7
## ✓ tidyr   1.1.3     ✓ stringr 1.4.0
## ✓ readr   1.4.0     ✓ forcats 0.5.1</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::explain() masks fastshap::explain()
## x dplyr::filter()  masks stats::filter()
## x dplyr::lag()     masks stats::lag()</code></pre>
<pre class="r"><code>library(tidymodels, quietly = TRUE)</code></pre>
<pre><code>## Registered S3 method overwritten by &#39;tune&#39;:
##   method                   from   
##   required_pkgs.model_spec parsnip</code></pre>
<pre><code>## ── Attaching packages ────────────────────────────────────── tidymodels 0.1.3 ──</code></pre>
<pre><code>## ✓ broom        0.7.7      ✓ rsample      0.1.0 
## ✓ dials        0.0.9      ✓ tune         0.1.5 
## ✓ infer        0.5.4      ✓ workflows    0.2.2 
## ✓ modeldata    0.1.0      ✓ workflowsets 0.0.2 
## ✓ parsnip      0.1.6      ✓ yardstick    0.0.8 
## ✓ recipes      0.1.16</code></pre>
<pre><code>## ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
## x scales::discard() masks purrr::discard()
## x dplyr::explain()  masks fastshap::explain()
## x dplyr::filter()   masks stats::filter()
## x recipes::fixed()  masks stringr::fixed()
## x dplyr::lag()      masks stats::lag()
## x yardstick::spec() masks readr::spec()
## x recipes::step()   masks stats::step()
## • Use tidymodels_prefer() to resolve common conflicts.</code></pre>
<pre class="r"><code>library(kableExtra)   # Just for the Markdown document</code></pre>
<pre><code>## 
## Attaching package: &#39;kableExtra&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     group_rows</code></pre>
<p>Next I loaded a script containing some functions that I defined (available on GitHub).</p>
<pre class="r"><code>source(&quot;./helper-functions/tidy-ml-evaluation-funs.R&quot;)</code></pre>
<p>At this point I was ready to start with data exploration.</p>
</div>
<div id="data-exploration" class="section level1">
<h1>Data Exploration</h1>
<p>First I loaded the data and made some small adjustments, for example, I learned in my tinkering that there are some unused levels in the “Neighborhood” variable.</p>
<pre class="r"><code># Load the Ames data set
data(ames)

# Convert month variable to a factor and set the largest category of each
# factor to that factor&#39;s base level (for contrast matrix for LM)
housing &lt;- ames |&gt;
  janitor::clean_names() |&gt;
  mutate(
    mo_sold = as_factor(mo_sold),
    across(where(is.factor), ~ fct_drop(.x) |&gt; fct_infreq())
  )

neighborhoods &lt;- table(ames$Neighborhood) |&gt; 
  enframe(name = &quot;Neighborhood&quot;, value = &quot;Count&quot;) |&gt; 
  arrange(Count) |&gt;
  slice(1:6)

hl_neigh_rows &lt;- which(neighborhoods$Count == 0)

neighborhoods |&gt;
  kable(booktabs = TRUE) |&gt;
  kable_styling() |&gt;
  row_spec(hl_neigh_rows, bold = T, color = &quot;black&quot;, background = &quot;yellow&quot;)</code></pre>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Neighborhood
</th>
<th style="text-align:right;">
Count
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;color: black !important;background-color: yellow !important;">
Hayden_Lake
</td>
<td style="text-align:right;font-weight: bold;color: black !important;background-color: yellow !important;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
Landmark
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
Green_Hills
</td>
<td style="text-align:right;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
Greens
</td>
<td style="text-align:right;">
8
</td>
</tr>
<tr>
<td style="text-align:left;">
Blueste
</td>
<td style="text-align:right;">
10
</td>
</tr>
<tr>
<td style="text-align:left;">
Northpark_Villa
</td>
<td style="text-align:right;">
23
</td>
</tr>
</tbody>
</table>
<p>Next I just wanted to check whether there were any missing values in the data (there shouldn’t be).</p>
<pre class="r"><code>any(is.na(housing))</code></pre>
<pre><code>## [1] FALSE</code></pre>
<p>Then I wanted to see how many categories there were in each discrete variable to determine whether there might be any near-zero variance issues. When there are too many categories in a discrete variable, that variable would not do a good job of grouping (how informative is a category of size 1?) and if there are too few variables relative to the observation count then it’s likely that a small number of categories will be too dominant and possibly mask the effects of other categories.</p>
<pre class="r"><code>select(housing, -sale_price) |&gt;
  select_if(is.factor) |&gt;
  summarise(across(everything(), ~ n_distinct(.x, na.rm = TRUE))) |&gt;
  pivot_longer(
    everything(), 
    names_to = &quot;variable&quot;, 
    values_to = &quot;num_categories&quot;
  ) |&gt;
  ggplot(aes(x = num_categories, y = fct_reorder(variable, num_categories))) +
  geom_bar(stat = &quot;identity&quot;, width = 0.8) +
  labs(
    y = &quot;Variable&quot;,
    x = &quot;Number of Categories&quot;,
    title = &quot;Number of Categories in Each Factor Variable&quot;
  ) +
  ml_eval_theme()</code></pre>
<p><img src="tidy-ml-evaluation_files/figure-html/discrete_counts-1.png" width="1152" /></p>
<p>There are a few concerning variables, so next I’ll do a quick check for near-zero variance using the parameters from the <a href="https://recipes.tidymodels.org/reference/step_nzv.html">recipes::step_nzv() function</a>.</p>
<pre class="r"><code># Check for near-zero variance
uniqueCut &lt;- select(housing, -sale_price) |&gt;
  select_if(is.factor) |&gt;
  pivot_longer(everything(), names_to = &quot;variable&quot;, values_to = &quot;category&quot;) |&gt; 
  group_by(variable) |&gt;
  summarise(uniqueCut = (n_distinct(category) * 100) / n(), .groups = &quot;drop&quot;)

freqCut &lt;- select(housing, -sale_price) |&gt;
  select_if(is.factor) |&gt;
  pivot_longer(everything(), names_to = &quot;variable&quot;, values_to = &quot;category&quot;) |&gt;
  count(variable, category, name = &quot;count&quot;) |&gt;
  group_by(variable) |&gt;
  slice_max(count, n = 2, with_ties = FALSE) |&gt;
  mutate(rank = c(&quot;first&quot;, &quot;second&quot;)) |&gt;
  ungroup() |&gt;
  select(-category) |&gt;
  pivot_wider(names_from = rank, values_from = count) |&gt;
  mutate(freqCut = first / second)

housing_nzv &lt;- left_join(freqCut, uniqueCut, by = &quot;variable&quot;) |&gt;
  mutate(nzv = as.numeric(uniqueCut &lt; 10 &amp; freqCut &gt; 19))

housing_nzv_counts &lt;- housing_nzv |&gt;
  count(nzv)

hl_nzv_rows &lt;- which(housing_nzv_counts$nzv == 1)

kable(slice(housing_nzv, 1:6), booktabs = TRUE) |&gt; kable_styling()</code></pre>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
variable
</th>
<th style="text-align:right;">
first
</th>
<th style="text-align:right;">
second
</th>
<th style="text-align:right;">
freqCut
</th>
<th style="text-align:right;">
uniqueCut
</th>
<th style="text-align:right;">
nzv
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
alley
</td>
<td style="text-align:right;">
2732
</td>
<td style="text-align:right;">
120
</td>
<td style="text-align:right;">
22.766667
</td>
<td style="text-align:right;">
0.1023891
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
bldg_type
</td>
<td style="text-align:right;">
2425
</td>
<td style="text-align:right;">
233
</td>
<td style="text-align:right;">
10.407725
</td>
<td style="text-align:right;">
0.1706485
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
bsmt_cond
</td>
<td style="text-align:right;">
2616
</td>
<td style="text-align:right;">
122
</td>
<td style="text-align:right;">
21.442623
</td>
<td style="text-align:right;">
0.2047782
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
bsmt_exposure
</td>
<td style="text-align:right;">
1906
</td>
<td style="text-align:right;">
418
</td>
<td style="text-align:right;">
4.559809
</td>
<td style="text-align:right;">
0.1706485
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
bsmt_fin_type_1
</td>
<td style="text-align:right;">
859
</td>
<td style="text-align:right;">
851
</td>
<td style="text-align:right;">
1.009401
</td>
<td style="text-align:right;">
0.2389078
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
bsmt_fin_type_2
</td>
<td style="text-align:right;">
2499
</td>
<td style="text-align:right;">
106
</td>
<td style="text-align:right;">
23.575472
</td>
<td style="text-align:right;">
0.2389078
</td>
<td style="text-align:right;">
1
</td>
</tr>
</tbody>
</table>
<pre class="r"><code>kable(housing_nzv_counts, booktabs = TRUE) |&gt; 
  kable_styling() |&gt;
  row_spec(hl_nzv_rows, bold = T, color = &quot;black&quot;, background = &quot;yellow&quot;)</code></pre>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
nzv
</th>
<th style="text-align:right;">
n
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
28
</td>
</tr>
<tr>
<td style="text-align:right;font-weight: bold;color: black !important;background-color: yellow !important;">
1
</td>
<td style="text-align:right;font-weight: bold;color: black !important;background-color: yellow !important;">
13
</td>
</tr>
</tbody>
</table>
<p>Next I want to look at the distributions of numeric data with violin plots from <a href="https://ggplot2.tidyverse.org/reference/geom_violin.html">ggplot2</a>.</p>
<pre class="r"><code>select(housing, where(is.numeric)) |&gt;
  pivot_longer(everything(), names_to = &quot;variable&quot;, values_to = &quot;value&quot;) |&gt;
  ggplot(aes(x = variable, y = value)) +
  geom_violin(fill = &quot;gray&quot;) +
  facet_wrap(~ variable, scales = &quot;free&quot;, ncol = 5) +
  labs(
    y = NULL,
    x = NULL,
    title = &quot;Distributions of Numeric Variables&quot;
  ) +
  ml_eval_theme() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="tidy-ml-evaluation_files/figure-html/num_distributions-1.png" width="1152" /></p>
<p>While it looks like some of the numeric variables are multimodal or have skewed distributions, the real concern is that <code>sales_price</code>, the target variable, looks a bit right skewed (as financial data often are). I’ll normalize the numeric explanatory variables in my recipe later and perform a <a href="https://statisticaloddsandends.wordpress.com/2021/02/19/the-box-cox-and-yeo-johnson-transformations-for-continuous-variables/">Yeo-Johnson transformation</a> on the target variable for modeling.</p>
<p>Now that I have an idea of what the variables look like individually, I’m going to see if there are any relationships that might suggest multicollinearity or redundancy. I’ll start with the discrete variables.</p>
<pre class="r"><code>factor_names &lt;- select(housing, -sale_price) |&gt;
  select_if(is.factor) |&gt;
  names()

chi_sq_dat &lt;- crossing(var1 = factor_names, var2 = factor_names) |&gt;
  mutate(
    chi_sq_results = map2(
      var1,
      var2,
      ~ select(housing, any_of(c(.x, .y))) |&gt;
        table() |&gt;
        chisq.test() |&gt;
        broom::tidy()
    )
  ) |&gt;
  unnest(chi_sq_results) |&gt;
  select(var1, var2, p.value) |&gt;
  pivot_wider(names_from = var2, values_from = p.value) |&gt;
  column_to_rownames(&quot;var1&quot;)

chi_sq_dat[!upper.tri(chi_sq_dat)] &lt;- NA

chi_sq_dat |&gt;
  rownames_to_column(&quot;var1&quot;) |&gt;
  pivot_longer(-var1, names_to = &quot;var2&quot;, values_to = &quot;p.value&quot;) |&gt;
  drop_na(p.value) |&gt;
  ggplot(aes(fct_rev(var2), var1, color = p.value)) +
  geom_point(size = 3) +
  scale_color_viridis_c(direction = -1) +
  labs(title = &quot;Chi-square Plot of Categorical Variables&quot;, color = &quot;P-value&quot;) +
  ml_eval_theme() +
  theme(
    axis.title = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.border = element_blank(),
    axis.line = element_line()
  )</code></pre>
<p><img src="tidy-ml-evaluation_files/figure-html/chi_sq_viz-1.png" width="1152" /></p>
<p>A low p-value from a chi-square test indicates non-independence between 2 variables and this plot shows that there seems to be quite a lot of interdependence among these categorical variables. Next I’ll look at the relationships among the numeric variables with a correlation plot.</p>
<pre class="r"><code>select(housing, -sale_price) |&gt;
  select_if(is.numeric) |&gt;
  corrr::correlate(method = &quot;spearman&quot;, use = &quot;pairwise.complete.obs&quot;) |&gt;
  corrr::rearrange(absolute = FALSE) |&gt;
  corrr::shave() |&gt;
  corrr::rplot(colors = c(&quot;red&quot;, &quot;white&quot;, &quot;blue&quot;)) +
  labs(title = &quot;Correlation Plot of Numeric Variables&quot;, color = &quot;Correlation&quot;) +
  ml_eval_theme() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.border = element_blank(),
    axis.line = element_line()
  )</code></pre>
<pre><code>## 
## Correlation method: &#39;spearman&#39;
## Missing treated using: &#39;pairwise.complete.obs&#39;</code></pre>
<pre><code>## Don&#39;t know how to automatically pick scale for object of type noquote. Defaulting to continuous.</code></pre>
<p><img src="tidy-ml-evaluation_files/figure-html/corr_viz-1.png" width="1152" /></p>
<p>There seems to be less of an interdependence problem among the numeric variables. To deal with this problem in both types of variables I’ll use the <a href="https://stevenpawley.github.io/recipeselectors/reference/step_select_mrmr.html">recipeselectors::step_mrmr() function</a> step in my pre-processing recipe.</p>
<p>Now I’ll move on to preparing the data for modeling.</p>
</div>
<div id="modeling-prep" class="section level1">
<h1>Modeling Prep</h1>
<p>First I’ll split the data for training and testing and further split the training data into cross-validation folds.</p>
<pre class="r"><code># Set the random number seed
set.seed(485)

# Split the data
housing_split &lt;- initial_split(housing, prop = 0.75)
housing_train &lt;- training(housing_split)
housing_test &lt;- testing(housing_split)

# Create the CV dataframe
housing_folds &lt;- vfold_cv(housing_train, v = 10)</code></pre>
<p>Next I’ll write my pre-processing recipes; one for each type of model. The only difference between the two recipes is that in the linear model recipe I set <code>one_hot = FALSE</code> to keep the reference level out of the contrast matrix. The steps are as follows:</p>
<ol style="list-style-type: decimal">
<li>Define roles for the outcome and predictor variables</li>
<li>Remove near-zero-variance variables</li>
<li>Normalize all numeric predictors</li>
<li>Perform a Yeo-Johnson transformation on the target variable</li>
<li>Apply minimum Redundancy Maximum Relevance (mRMR) feature selection</li>
<li>Convert discrete variables to dummy variables</li>
</ol>
<pre class="r"><code># XGBoost recipe
xgb_rec &lt;- recipe(housing_train) |&gt;
  update_role(sale_price, new_role = &quot;outcome&quot;) |&gt;
  update_role(-has_role(&quot;outcome&quot;), new_role = &quot;predictor&quot;) |&gt;
  step_nzv(all_predictors()) |&gt;
  step_normalize(all_numeric_predictors()) |&gt;
  step_YeoJohnson(all_outcomes()) |&gt;
  recipeselectors::step_select_mrmr(
    all_predictors(),
    outcome = &quot;sale_price&quot;,
    threshold = 0.9,
    skip = TRUE
  ) |&gt;
  step_dummy(all_nominal_predictors(), one_hot = TRUE)

# Linear Model recipe
num_steps &lt;- length(xgb_rec$steps)
lm_rec &lt;- xgb_rec
lm_rec$steps[[num_steps]] &lt;- update(lm_rec$steps[[num_steps]], one_hot = FALSE)</code></pre>
<p>Next I want to generate a tuning grid for the XGB model. To limit the number of features selected randomly at each node I’ll first get the number of features that will be in the data after the pre-processing recipe has been applied. I also set the range for the learning rate a bit arbitrarily because I found that the default range resulted in the model learning too quickly and not keeping enough information from early iterations.</p>
<pre class="r"><code># Get the number of features in the training data for XGB tuning grid
n_features &lt;- bake(prep(xgb_rec), new_data = housing_train) |&gt;
  ncol() |&gt;
  magrittr::subtract(1) |&gt;
  sqrt()

# Create a tuning grid for XGB
set.seed(55)
xgb_grid &lt;- grid_random(
  mtry(c(1, floor(n_features))),   # Range of number of features to try
  trees(),   # Range of number of trees
  learn_rate(range = c(-7, 1)),   # Learning rate
  loss_reduction(),
  size = 50
)</code></pre>
<p>Now I’ll create the <a href="https://workflows.tidymodels.org/">workflow</a> objects that I’ll use in model tuning and evaluation.</p>
<pre class="r"><code># Create model objects for both XGB and LM
xgb_mod &lt;- boost_tree(
  mtry = tune(), 
  trees = tune(), 
  learn_rate = tune(),
  loss_reduction = tune(),
  mode = &quot;regression&quot;
) |&gt;
  set_engine(&quot;xgboost&quot;)

lm_mod &lt;- linear_reg(mode = &quot;regression&quot;) |&gt; set_engine(&quot;lm&quot;)

# Create workflow objects for tuning
xgb_wflow &lt;- workflow() |&gt; add_recipe(xgb_rec) |&gt; add_model(xgb_mod)
lm_wflow &lt;- workflow() |&gt; add_recipe(lm_rec) |&gt; add_model(lm_mod)</code></pre>
</div>
<div id="modeling" class="section level1">
<h1>Modeling</h1>
<div id="tuning-the-models" class="section level2">
<h2>Tuning the Models</h2>
<p>Because model tuning can be quite computationally intensive (and time consuming) even for a small example like the one I’m working with, I first set up a parallel back end to run simple processes simultaneously. Some important things to note are that I had to ensure that the <a href="https://stevenpawley.github.io/recipeselectors/index.html">recipeselectors</a> package was available to each processor and that I set the same random seed on each processor for reproducibility. Once that’s done, I tune the models.</p>
<pre class="r"><code># Register and set up the parallel backend
cl &lt;- parallel::makePSOCKcluster(parallel::detectCores(logical = FALSE) - 1)
doParallel::registerDoParallel(cl)
parallel::clusterEvalQ(cl, library(recipeselectors))</code></pre>
<pre><code>## [[1]]
##  [1] &quot;recipeselectors&quot; &quot;recipes&quot;         &quot;dplyr&quot;           &quot;stats&quot;          
##  [5] &quot;graphics&quot;        &quot;grDevices&quot;       &quot;utils&quot;           &quot;datasets&quot;       
##  [9] &quot;methods&quot;         &quot;base&quot;           
## 
## [[2]]
##  [1] &quot;recipeselectors&quot; &quot;recipes&quot;         &quot;dplyr&quot;           &quot;stats&quot;          
##  [5] &quot;graphics&quot;        &quot;grDevices&quot;       &quot;utils&quot;           &quot;datasets&quot;       
##  [9] &quot;methods&quot;         &quot;base&quot;           
## 
## [[3]]
##  [1] &quot;recipeselectors&quot; &quot;recipes&quot;         &quot;dplyr&quot;           &quot;stats&quot;          
##  [5] &quot;graphics&quot;        &quot;grDevices&quot;       &quot;utils&quot;           &quot;datasets&quot;       
##  [9] &quot;methods&quot;         &quot;base&quot;</code></pre>
<pre class="r"><code>parallel::clusterEvalQ(cl, set.seed(853))</code></pre>
<pre><code>## [[1]]
## NULL
## 
## [[2]]
## NULL
## 
## [[3]]
## NULL</code></pre>
<pre class="r"><code># Tune both models
xgb_tune &lt;- tune_grid(
  xgb_wflow,
  grid = xgb_grid,
  resamples = housing_folds,
  metrics = metric_set(rmse, rsq_trad)
)

lm_tune &lt;- fit_resamples(
  lm_wflow,
  resamples = housing_folds,
  metrics = metric_set(rmse, rsq_trad)
)</code></pre>
<p>I leave the parallel processing cluster because there are some processes ahead that will also require parallel processing.</p>
</div>
<div id="model-selection-and-fitting" class="section level2">
<h2>Model Selection and Fitting</h2>
<p>Now that the model hyperparameters have been tuned (at least for XGB) I can pull the models that performed best from our cross-validation process.</p>
<pre class="r"><code># Get the best models from each tuning process
best_models &lt;- list(xgb = xgb_tune, lm = lm_tune) |&gt;
  map(select_best, metric = &quot;rmse&quot;)

# Collect tuning metrics for each tuning process
tune_metrics &lt;- list(xgb = xgb_tune, lm = lm_tune) |&gt;
  map(collect_metrics)

# Fit the models with the best parameters to the entire training data set
final_wflows &lt;- map2(
  list(xgb = xgb_wflow, lm = lm_wflow),
  best_models,
  ~ finalize_workflow(.x, .y) |&gt; fit(data = housing_train)
)</code></pre>
</div>
<div id="model-evaluation" class="section level2">
<h2>Model Evaluation</h2>
<p>With the best performing models from cross-validation now fit to the entire training data set, I can evaluate these models against the test data.</p>
<pre class="r"><code># Evaluate each model with the test data and store &#39;last_fit&#39; objects
set.seed(485)
final_wflow_evals &lt;- map(
  final_wflows, 
  last_fit, 
  split = housing_split,
  metrics = metric_set(rmse, mae, mape, rsq_trad)
)</code></pre>
<p>Now I can see how each model performed on the test data.</p>
<pre class="r"><code># Generate a dataframe of model metrics to compare the two models
model_metrics &lt;- final_wflow_evals |&gt;
  map2_df(
    names(final_wflow_evals),
    ~ collect_metrics(.x) |&gt; 
      select(.metric, .estimate) |&gt; 
      pivot_wider(names_from = .metric, values_from = .estimate) |&gt;
      mutate(algorithm = .y) |&gt;
      relocate(algorithm)
  )</code></pre>
<p>It looks like the XGB model outperformed the Linear Model on every metric, but not by very much. Both seem to have performed pretty well at predicting home sale prices. It’s important to keep in mind here that the data were transformed, which is why the RMSE and MAE are so small. Now let’s go ahead and open these “black boxes”.</p>
</div>
</div>
<div id="opening-the-black-box" class="section level1">
<h1>Opening the “Black Box”</h1>
<div id="generate-shap-values" class="section level2">
<h2>Generate SHAP Values</h2>
<p>As stated earlier, this part of the analysis will be based on SHAP values. <a href="https://christophm.github.io/interpretable-ml-book/shapley.html">This explanation</a> from Christoph Molnar’s book <a href="https://christophm.github.io/interpretable-ml-book/">Interpretable Machine Learning</a> is a great primer on what SHAP values are and how they can help someone understand the effect of a given feature/variable on a prediction.</p>
<p>With that in mind, now that the models have been tuned, trained, and evaluated, I can generate SHAP values to understand what’s going on under the hood (kinda). Note that this is still being run in parallel until the end of this portion.</p>
<pre class="r"><code># Get matrices of training features for each model
training_features &lt;- final_wflows %&gt;% 
  map(~ pull_workflow_mold(.x) %&gt;% pluck(&quot;predictors&quot;))

# Initiate a multicore plan 
future::plan(&quot;cluster&quot;, workers = cl)

# Get SHAP values
shap &lt;- final_wflows %&gt;% 
  furrr::future_map(
    get_shap, 
    .progress = TRUE, 
    .options = furrr::furrr_options(seed = 44)
  )

# Get SHAP variable importance features
var_imp &lt;- shap %&gt;%
  map(get_shap_imp)

# Go back to sequential processing
future::plan(future::sequential)

# Close the connection to the cluster
parallel::stopCluster(cl)</code></pre>
</div>
<div id="plot-relationships-between-shap-and-the-training-data" class="section level2">
<h2>Plot Relationships Between SHAP and the Training Data</h2>
<p>I now have my SHAP values and can begin to visualize a few different things. The first visualization will be a <a href="https://christophm.github.io/interpretable-ml-book/shap.html#shap-summary-plot">SHAP summary plot</a>, which I also found in Christoph Molnar’s <a href="https://christophm.github.io/interpretable-ml-book/">Interpretable Machine Learning</a>. When I saw this plot I was amazed at how much information it actually contains once you grasp the dimensionality.</p>
<pre class="r"><code># Pull data from the outermost point on the SHAP summary plot
point_dat_xgb &lt;- get_shap_summary(
  var_imp$xgb, 
  shap$xgb, 
  training_features$xgb, 
  max_features = 1
) |&gt;
  slice_max(shap_value, with_ties = FALSE)

point_dat_lm &lt;- get_shap_summary(
  var_imp$lm, 
  shap$lm, 
  training_features$lm, 
  max_features = 1
) |&gt;
  slice_max(shap_value, with_ties = FALSE)

# Put the data from that point into a string object
point_annotation_xgb &lt;- str_glue(
  &quot;Row = {point_dat_xgb$id}
  Variable = {point_dat_xgb$variable}
  SHAP Value = {round(point_dat_xgb$shap_value, 3)}
  Feature Value = {round(point_dat_xgb$feature_value, 3)}&quot;
)

point_annotation_lm &lt;- str_glue(
  &quot;Row = {point_dat_lm$id}
  Variable = {point_dat_lm$variable}
  SHAP Value = {round(point_dat_lm$shap_value, 3)}
  Feature Value = {round(point_dat_lm$feature_value, 3)}&quot;
)

# Create SHAP summaries containing data frames and plots
shap_summary_plots &lt;- list(
  var_imp, 
  shap, 
  training_features
) |&gt;
  pmap(get_shap_summary, max_features = 10) %&gt;%
  map2(c(&quot;XG Boost&quot;, &quot;Linear Regression&quot;), plot_shap_summary)

total_bsmt_sf_pdp &lt;- final_wflows |&gt;
  map2(c(&quot;XG Boost&quot;, &quot;Linear Regression&quot;), plot_pdp, pred_var = total_bsmt_sf)

# Generate the SHAP summary plot with an annotation for the outermost point
set.seed(23)
shap_summary_plots$xgb + 
  geom_segment(
    aes(x = 0.5, xend = 0.575, y = 8, yend = 10.01), 
    color = &quot;black&quot;,
    arrow = arrow(length = unit(0.03, &quot;npc&quot;))
  ) +
  annotate(
    geom = &quot;text&quot;, 
    x = 0.46, 
    y = 6.8, label = point_annotation_xgb, 
    hjust = &quot;center&quot;
  )</code></pre>
<p><img src="tidy-ml-evaluation_files/figure-html/explain_shap_summary-1.png" width="1152" /></p>
<pre class="r"><code>set.seed(23)
shap_summary_plots$lm + 
  geom_segment(
    aes(x = 0.79, xend = 0.9, y = 8, yend = 10), 
    color = &quot;black&quot;,
    arrow = arrow(length = unit(0.03, &quot;npc&quot;))
  ) +
  annotate(
    geom = &quot;text&quot;, 
    x = 0.8, 
    y = 6.8, label = point_annotation_lm, 
    hjust = &quot;center&quot;
  )</code></pre>
<p><img src="tidy-ml-evaluation_files/figure-html/explain_shap_summary-2.png" width="1152" /></p>
<p>The first plot above shows that row 1840 has a positive SHAP value of 0.5800548 for the gr_liv_area (0.096) in the XGB model, which had an above average value of 4.5232897 in the training data. When considering all the observations collectively the feature value is ideally positively related with the SHAP value. Next I’ll look at partial dependence plots to show the effect that the <code>gr_liv_area</code> has on <code>sale_price</code> according to each model.</p>
<pre class="r"><code>gr_liv_area_pdp &lt;- final_wflows |&gt;
  map2(c(&quot;XG Boost&quot;, &quot;Linear Regression&quot;), plot_pdp, pred_var = gr_liv_area)

gr_liv_area_pdp$xgb</code></pre>
<p><img src="tidy-ml-evaluation_files/figure-html/pdp_plots-1.png" width="1152" /></p>
<pre class="r"><code>gr_liv_area_pdp$lm</code></pre>
<p><img src="tidy-ml-evaluation_files/figure-html/pdp_plots-2.png" width="1152" /></p>
<p>According to both models the <code>gr_liv_area</code> variable positively effects the predicted sale price of a home in the training data, which seems consistent with general knowledge about home prices given that <code>gr_liv_area</code> is a measure of the above ground living area (more commonly known as “square footage”). It’s important to note, however, that, unlike the coefficient in a regression model, one should not make inferences from a partial dependency beyond the dimensions of the training data. A partial dependency plot is meant only to provide an overview on the broad relationship between an explanatory variable and the target variable.</p>
<p>Lastly, I can look at how each feature affects a particular observation with a contribution plot. I’ll consider the house observed in row 2049 of the training data set.</p>
<pre class="r"><code>obs_2409_contrib &lt;- shap |&gt;
  map2(
    c(&quot;XG Boost&quot;, &quot;Linear Regression&quot;), 
    get_contributions, 
    rnum = 2049, 
    nfeat = 15 
  )

obs_2409_contrib$xgb$contrib_plot</code></pre>
<p><img src="tidy-ml-evaluation_files/figure-html/contrib_plots-1.png" width="1152" /></p>
<pre class="r"><code>obs_2409_contrib$lm$contrib_plot</code></pre>
<p><img src="tidy-ml-evaluation_files/figure-html/contrib_plots-2.png" width="1152" /></p>
<p>The above XG Boost contribution plot shows that <code>total_bsmt_sf</code> had the largest positive effect on the predicted sale price of the sale in observation 2049 and having <code>garage_finish_Unf</code> (having an unfinished garage) had the largest negative effect. The Linear Regression contribution plot shows that <code>gr_liv_area</code> had the largest positive effect and <code>neighborhood_Brookside</code> had the largest negative effect on the predicted sale price. However, it’s interesting to note that <code>garage_finish_Fin</code>, the opposite of <code>garage_finish_Unf</code>, had a negative effect in the Linear Regression.</p>
</div>
</div>
<div id="final-thoughts" class="section level1">
<h1>Final Thoughts</h1>
<p>While these methods of looking into machine learning algorithms are not designed for inference, they do go a long way in helping to elucidate the relationships or patterns that machine learning algorithms find. They help answer the questions about why some predictions come out the way that they do, whether they make sense or not.</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
