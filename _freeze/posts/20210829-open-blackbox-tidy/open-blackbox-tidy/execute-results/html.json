{
  "hash": "19a6935ebb008d97e1f9f7b74cff7f9f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Opening the ML ‘Black Box’ with Shapley Values\"\nsubtitle: \"A Tidy Approach\"\nauthor: \"Arcenis Rojas\"\ndate: \"8/29/2021\"\nformat: \n  html:\n    link-external-newwindow: true\n    toc: true\n    toc_float: true\n    fig-width: 12\n    fig-height: 8\neditor: visual\nexecute:\n  warning: false\n  error: false\n---\n\n\n## Introduction / Motivation\n\n![Blackbox over neural network vector](images/ml-blackbox.png){fig-alt=\"Blackbox over neural network vector\" fig-align=\"center\" width=\"443\"}\n\nRecently I worked on a project which required explanation of ML algorithms more precisely than with precision (I've heard you should always open with a bad joke). Being fairly new to the world of ML, I wasn't aware of many ways to do that, but in my research I found [DALEX](https://dalex.drwhy.ai/) developed by [MI2DataLab](https://github.com/ModelOriented/). I was impressed, surprised, and excited. I very quickly developed some code for my project and even built a [modelStudio](https://modelstudio.drwhy.ai/) dashboard as a proof of concept. Some of the advantages of [DALEX](https://dalex.drwhy.ai/) are that it...\n\n-   is model agnostic with comparable results across models\n-   has an easy, consistent interface\n-   produces easily interpretable visualizations\n-   can generates HTML widgets/pages through modelStudio\n-   provides Various ways to look at contributions of each observation to model predictions\n\nUpon presenting my proof of concept, though, I learned about some other project requirements that highlighted two disadvantages of [DALEX](https://dalex.drwhy.ai/). The R package does not...\n\n-   run in parallel\n-   provide SHAP values\n-   work natively (or easily) with [Tidymodel](https://www.tidymodels.org/) objects\n\nThese disadvantages were enough to have me go back to the drawing board. I wondered if there were other ways to get the same types of visualizations and model break-downs through or from other R packages. I found...\n\n-   [fastshap](https://bgreenwell.github.io/fastshap/articles/fastshap.html) for computing Shapley values\n-   [pdp](https://bgreenwell.github.io/pdp/articles/pdp.html) for generating partial dependence plots\n-   [vip](https://koalaverse.github.io/vip/articles/vip.html) for generating variable importance using different methods\n-   [breakDown](https://pbiecek.github.io/breakDown/) for explaining variable contributions to individual predictions\n\nSince I was using Shapley values as a basis on which to explain everything I used only [fastshap](https://bgreenwell.github.io/fastshap/articles/fastshap.html) and [pdp](https://bgreenwell.github.io/pdp/articles/pdp.html), but found that [vip](https://koalaverse.github.io/vip/articles/vip.html) would work well if I wanted to use another method for computing variable importance like permutation. I found it a bit challenging to use [breakDown](https://pbiecek.github.io/breakDown/) with [Tidymodel](https://www.tidymodels.org/) objects, otherwise, it was pretty easy to work with.\n\nI'm going to demonstrate how I used these packages to \"open the black box\" of ML algorithms. In the example below I'll show how I did it using an XG Boost and a linear model algorithm since 'lm' is very standard and XG Boost can present some challenging data formatting requirements. I'll be using the [Ames Housing Data](https://modeldata.tidymodels.org/reference/ames.html) included in the [modeldata](https://modeldata.tidymodels.org/index.html) package. I'm using this version rather than that from the [AmesHousing package](https://cran.r-project.org/web/packages/AmesHousing/AmesHousing.pdf) because the good folks at [RStudio](https://www.rstudio.com/) who work on [Tidymodels](https://www.tidymodels.org/) did a great job of cleaning up the data a bit (thank you!) in their version and I didn't want to spend a lot of time doing that for this demo. Also, I chose this data set because it has some things in common with the data that I used in the aforementioned project that prompted this work such as having mixed data types (discrete and numeric) in the explanatory variables, a large enough number of observations for training (and tuning) and testing a model, and some problems with multicollinearity (or redundancy) in the explanatory variables. As a quick aside, I'm also very grateful to the folks that work on the [Tidyverse](https://www.tidyverse.org/) of packages; I use these in nearly every R session.\n\n## Getting Started\n\nPrior to diving into the data, first I loaded packages that I would use throughout the code.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(tidyverse, tidymodels, yardstick, fastshap, kableExtra)\nconflicted::conflict_prefer(\"filter\", \"dplyr\")\nconflicted::conflict_prefer(\"select\", \"dplyr\")\ntidymodels_prefer()\n```\n:::\n\n\nNext I loaded a script containing some functions that I defined [(available on GitHub)](https://github.com/arcenis-r/ajr-portfolio/tree/master/helper-functions).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"./tidy-ml-evaluation-funs.R\")\n```\n:::\n\n\nAt this point I was ready to start with data exploration.\n\n## Data Exploration\n\nFirst I loaded the data and made some small adjustments, for example, I learned in my tinkering that there are some unused levels in the \"Neighborhood\" variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the Ames data set\ndata(ames)\n\n# Convert month variable to a factor and set the largest category of each\n# factor to that factor's base level (for contrast matrix for LM)\nhousing <- ames |>\n  janitor::clean_names() |>\n  mutate(\n    mo_sold = as_factor(mo_sold),\n    across(where(is.factor), \\(x) fct_drop(x) |> fct_infreq())\n  )\n\nneighborhoods <- table(ames$Neighborhood) |> \n  enframe(name = \"Neighborhood\", value = \"Count\") |> \n  arrange(Count) |>\n  slice(1:6)\n\nhl_neigh_rows <- which(neighborhoods$Count == 0)\n\nneighborhoods |>\n  kable(booktabs = TRUE) |>\n  kable_styling() |>\n  row_spec(hl_neigh_rows, bold = T, color = \"black\", background = \"yellow\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Neighborhood </th>\n   <th style=\"text-align:right;\"> Count </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;color: black !important;background-color: yellow !important;\"> Hayden_Lake </td>\n   <td style=\"text-align:right;font-weight: bold;color: black !important;background-color: yellow !important;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Landmark </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Green_Hills </td>\n   <td style=\"text-align:right;\"> 2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Greens </td>\n   <td style=\"text-align:right;\"> 8 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Blueste </td>\n   <td style=\"text-align:right;\"> 10 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Northpark_Villa </td>\n   <td style=\"text-align:right;\"> 23 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nNext I just wanted to check whether there were any missing values in the data (there shouldn't be).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nany(is.na(housing))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\nThen I wanted to see how many categories there were in each discrete variable to determine whether there might be any near-zero variance issues. When there are too many categories in a discrete variable, that variable would not do a good job of grouping (how informative is a category of size 1?) and if there are too few variables relative to the observation count then it's likely that a small number of categories will be too dominant and possibly mask the effects of other categories.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselect(housing, -sale_price) |>\n  select_if(is.factor) |>\n  summarise(across(everything(), \\(x) n_distinct(x, na.rm = TRUE))) |>\n  pivot_longer(\n    everything(), \n    names_to = \"variable\", \n    values_to = \"num_categories\"\n  ) |>\n  ggplot(aes(x = num_categories, y = fct_reorder(variable, num_categories))) +\n  geom_bar(stat = \"identity\", width = 0.8) +\n  labs(\n    y = \"Variable\",\n    x = \"Number of Categories\",\n    title = \"Number of Categories in Each Factor Variable\"\n  ) +\n  ml_eval_theme()\n```\n\n::: {.cell-output-display}\n![](open-blackbox-tidy_files/figure-html/discrete-counts-1.png){width=1152}\n:::\n:::\n\n\nThere are a few concerning variables, so next I'll do a quick check for near-zero variance using the parameters from the [recipes::step_nzv() function](https://recipes.tidymodels.org/reference/step_nzv.html).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check for near-zero variance\nuniqueCut <- select(housing, -sale_price) |>\n  select_if(is.factor) |>\n  pivot_longer(everything(), names_to = \"variable\", values_to = \"category\") |> \n  group_by(variable) |>\n  summarise(uniqueCut = (n_distinct(category) * 100) / n(), .groups = \"drop\")\n\nfreqCut <- select(housing, -sale_price) |>\n  select_if(is.factor) |>\n  pivot_longer(everything(), names_to = \"variable\", values_to = \"category\") |>\n  count(variable, category, name = \"count\") |>\n  group_by(variable) |>\n  slice_max(count, n = 2, with_ties = FALSE) |>\n  mutate(rank = c(\"first\", \"second\")) |>\n  ungroup() |>\n  select(-category) |>\n  pivot_wider(names_from = rank, values_from = count) |>\n  mutate(freqCut = first / second)\n\nhousing_nzv <- left_join(freqCut, uniqueCut, by = \"variable\") |>\n  mutate(nzv = as.numeric(uniqueCut < 10 & freqCut > 19))\n\nhousing_nzv_counts <- housing_nzv |>\n  count(nzv)\n\nhl_nzv_rows <- which(housing_nzv_counts$nzv == 1)\n\nkable(slice(housing_nzv, 1:6), booktabs = TRUE) |> kable_styling()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> variable </th>\n   <th style=\"text-align:right;\"> first </th>\n   <th style=\"text-align:right;\"> second </th>\n   <th style=\"text-align:right;\"> freqCut </th>\n   <th style=\"text-align:right;\"> uniqueCut </th>\n   <th style=\"text-align:right;\"> nzv </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> alley </td>\n   <td style=\"text-align:right;\"> 2732 </td>\n   <td style=\"text-align:right;\"> 120 </td>\n   <td style=\"text-align:right;\"> 22.766667 </td>\n   <td style=\"text-align:right;\"> 0.1023891 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> bldg_type </td>\n   <td style=\"text-align:right;\"> 2425 </td>\n   <td style=\"text-align:right;\"> 233 </td>\n   <td style=\"text-align:right;\"> 10.407725 </td>\n   <td style=\"text-align:right;\"> 0.1706485 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> bsmt_cond </td>\n   <td style=\"text-align:right;\"> 2616 </td>\n   <td style=\"text-align:right;\"> 122 </td>\n   <td style=\"text-align:right;\"> 21.442623 </td>\n   <td style=\"text-align:right;\"> 0.2047782 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> bsmt_exposure </td>\n   <td style=\"text-align:right;\"> 1906 </td>\n   <td style=\"text-align:right;\"> 418 </td>\n   <td style=\"text-align:right;\"> 4.559809 </td>\n   <td style=\"text-align:right;\"> 0.1706485 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> bsmt_fin_type_1 </td>\n   <td style=\"text-align:right;\"> 859 </td>\n   <td style=\"text-align:right;\"> 851 </td>\n   <td style=\"text-align:right;\"> 1.009401 </td>\n   <td style=\"text-align:right;\"> 0.2389078 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> bsmt_fin_type_2 </td>\n   <td style=\"text-align:right;\"> 2499 </td>\n   <td style=\"text-align:right;\"> 106 </td>\n   <td style=\"text-align:right;\"> 23.575472 </td>\n   <td style=\"text-align:right;\"> 0.2389078 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\nkable(housing_nzv_counts, booktabs = TRUE) |> \n  kable_styling() |>\n  row_spec(hl_nzv_rows, bold = T, color = \"black\", background = \"yellow\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> nzv </th>\n   <th style=\"text-align:right;\"> n </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 28 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;font-weight: bold;color: black !important;background-color: yellow !important;\"> 1 </td>\n   <td style=\"text-align:right;font-weight: bold;color: black !important;background-color: yellow !important;\"> 13 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nNext I want to look at the distributions of numeric data with violin plots from [ggplot2](https://ggplot2.tidyverse.org/reference/geom_violin.html).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselect(housing, where(is.numeric)) |>\n  pivot_longer(everything(), names_to = \"variable\", values_to = \"value\") |>\n  ggplot(aes(x = variable, y = value)) +\n  geom_violin(fill = \"gray\") +\n  facet_wrap(~ variable, scales = \"free\", ncol = 5) +\n  labs(\n    y = NULL,\n    x = NULL,\n    title = \"Distributions of Numeric Variables\"\n  ) +\n  ml_eval_theme() +\n  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())\n```\n\n::: {.cell-output-display}\n![](open-blackbox-tidy_files/figure-html/num-distributions-1.png){width=1152}\n:::\n:::\n\n\nWhile it looks like some of the numeric variables are multimodal or have skewed distributions, the real concern is that `sales_price`, the target variable, looks a bit right skewed (as financial data often are). I'll normalize the numeric explanatory variables in my recipe later and perform a [Yeo-Johnson transformation](https://statisticaloddsandends.wordpress.com/2021/02/19/the-box-cox-and-yeo-johnson-transformations-for-continuous-variables/) on the target variable for modeling.\n\nNow that I have an idea of what the variables look like individually, I'm going to see if there are any relationships that might suggest multicollinearity or redundancy. I'll start with the discrete variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactor_names <- select(housing, -sale_price, where(is.factor)) |>  names()\n\nchi_sq_dat <- crossing(var1 = factor_names, var2 = factor_names) |>\n  mutate(\n    chi_sq_results = map2(\n      var1,\n      var2,\n      \\(x, y) select(housing, any_of(c(x, y))) |>\n        table() |>\n        chisq.test() |>\n        broom::tidy()\n    )\n  ) |>\n  unnest(chi_sq_results) |>\n  select(var1, var2, p.value) |>\n  pivot_wider(names_from = var2, values_from = p.value) |>\n  column_to_rownames(\"var1\")\n\nchi_sq_dat[!upper.tri(chi_sq_dat)] <- NA\n\nchi_sq_dat |>\n  rownames_to_column(\"var1\") |>\n  pivot_longer(-var1, names_to = \"var2\", values_to = \"p.value\") |>\n  drop_na(p.value) |>\n  ggplot(aes(fct_rev(var2), var1, color = p.value)) +\n  geom_point(size = 3) +\n  scale_color_viridis_c(direction = -1) +\n  labs(title = \"Chi-square Plot of Categorical Variables\", color = \"P-value\") +\n  ml_eval_theme() +\n  theme(\n    axis.title = element_blank(),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.border = element_blank(),\n    axis.line = element_line()\n  )\n```\n\n::: {.cell-output-display}\n![](open-blackbox-tidy_files/figure-html/chi-sq-viz-1.png){width=1152}\n:::\n:::\n\n\nA low p-value from a chi-square test indicates non-independence between 2 variables and this plot shows that there seems to be quite a lot of interdependence among these categorical variables. Next I'll look at the relationships among the numeric variables with a correlation plot.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselect(housing, -sale_price) |>\n  select_if(is.numeric) |>\n  corrr::correlate(method = \"spearman\", use = \"pairwise.complete.obs\") |>\n  corrr::rearrange(absolute = FALSE) |>\n  corrr::shave() |>\n  corrr::rplot(colors = c(\"red\", \"white\", \"blue\")) +\n  labs(title = \"Correlation Plot of Numeric Variables\", color = \"Correlation\") +\n  ml_eval_theme() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.border = element_blank(),\n    axis.line = element_line()\n  )\n```\n\n::: {.cell-output-display}\n![](open-blackbox-tidy_files/figure-html/corrr-viz-1.png){width=1152}\n:::\n:::\n\n\nThere seems to be less of an interdependence problem among the numeric variables. To deal with this problem in both types of variables I'll use the [colino::step_mrmr()](https://stevenpawley.github.io/colino/reference/step_select_mrmr.html) function step in my pre-processing recipe.\n\nNow I'll move on to preparing the data for modeling.\n\n## Modeling Prep\n\nFirst I'll split the data for training and testing and further split the training data into cross-validation folds.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the random number seed\nset.seed(485)\n\n# Split the data\nhousing_split <- initial_split(housing, prop = 0.75)\nhousing_train <- training(housing_split)\nhousing_test <- testing(housing_split)\n\n# Create the CV dataframe\nhousing_folds <- vfold_cv(housing_train, v = 10)\n```\n:::\n\n\nNext I'll write my pre-processing recipes; one for each type of model. The only difference between the two recipes is that in the linear model recipe I set `one_hot = FALSE` to keep the reference level out of the contrast matrix. The steps are as follows:\n\n1.  Define roles for the outcome and predictor variables\n2.  Remove near-zero-variance variables\n3.  Normalize all numeric predictors\n4.  Perform a Yeo-Johnson transformation on the target variable\n5.  Apply minimum Redundancy Maximum Relevance (mRMR) feature selection\n6.  Convert discrete variables to dummy variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# XGBoost recipe\nxgb_rec <- recipe(housing_train) |>\n  update_role(sale_price, new_role = \"outcome\") |>\n  update_role(-has_role(\"outcome\"), new_role = \"predictor\") |>\n  step_nzv(all_predictors()) |>\n  step_normalize(all_numeric_predictors()) |>\n  step_YeoJohnson(all_outcomes()) |>\n  colino::step_select_mrmr(\n    all_predictors(),\n    outcome = \"sale_price\",\n    threshold = 0.9,\n    skip = TRUE\n  ) |>\n  step_dummy(all_nominal_predictors(), one_hot = TRUE)\n\n# Linear Model recipe\nnum_steps <- length(xgb_rec$steps)\nlm_rec <- xgb_rec\nlm_rec$steps[[num_steps]] <- update(lm_rec$steps[[num_steps]], one_hot = FALSE)\n```\n:::\n\n\nNext I want to generate a tuning grid for the XGB model. To limit the number of features selected randomly at each node I'll first get the number of features that will be in the data after the pre-processing recipe has been applied. I also set the range for the learning rate a bit arbitrarily because I found that the default range resulted in the model learning too quickly and not keeping enough information from early iterations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get the number of features in the training data for XGB tuning grid\nn_features <- bake(prep(xgb_rec), new_data = housing_train) |>\n  ncol() |>\n  magrittr::subtract(1) |>\n  sqrt()\n\n# Create a tuning grid for XGB\nset.seed(55)\nxgb_grid <- grid_random(\n  mtry(c(1, floor(n_features))),   # Range of number of features to try\n  trees(),   # Range of number of trees\n  learn_rate(range = c(-7, 1)),   # Learning rate\n  loss_reduction(),\n  size = 50\n)\n```\n:::\n\n\nNow I'll create the [workflow](https://workflows.tidymodels.org/) objects that I'll use in model tuning and evaluation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create model objects for both XGB and LM\nxgb_mod <- boost_tree(\n  mtry = tune(), \n  trees = tune(), \n  learn_rate = tune(),\n  loss_reduction = tune(),\n  mode = \"regression\"\n) |>\n  set_engine(\"xgboost\")\n\nlm_mod <- linear_reg(mode = \"regression\") |> set_engine(\"lm\")\n\n# Create workflow objects for tuning\nxgb_wflow <- workflow() |> add_recipe(xgb_rec) |> add_model(xgb_mod)\nlm_wflow <- workflow() |> add_recipe(lm_rec) |> add_model(lm_mod)\n```\n:::\n\n\n## Modeling\n\n### Tuning the Models\n\nBecause model tuning can be quite computationally intensive (and time consuming) even for a small example like the one I'm working with, I first set up a parallel back end to run simple processes simultaneously. Some important things to note are that I had to ensure that the [colino](https://stevenpawley.github.io/colino/index.html) package was available to each processor and that I set the same random seed on each processor for reproducibility. Once that's done, I tune the models.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Register and set up the parallel backend\ncl <- parallel::makePSOCKcluster(parallel::detectCores(logical = FALSE) - 1)\ndoParallel::registerDoParallel(cl)\ninvisible(parallel::clusterEvalQ(cl, set.seed(853)))\n\n# Tune both models\nxgb_tune <- tune_grid(\n  xgb_wflow,\n  grid = xgb_grid,\n  resamples = housing_folds,\n  metrics = yardstick::metric_set(rmse, rsq_trad),\n  control = control_grid(allow_par = TRUE, parallel_over = \"everything\")\n)\n\nlm_tune <- fit_resamples(\n  lm_wflow,\n  resamples = housing_folds,\n  metrics = metric_set(rmse, rsq_trad),\n  control = control_grid(allow_par = TRUE, parallel_over = \"resamples\")\n)\n\n# Close the connection to the cluster\ndoParallel::stopImplicitCluster()\n```\n:::\n\n\n### Model Selection and Fitting\n\nNow that the model hyperparameters have been tuned (at least for XGB) I can pull the models that performed best from our cross-validation process.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get the best models from each tuning process\nbest_models <- list(xgb = xgb_tune, lm = lm_tune) |>\n  map(select_best, metric = \"rmse\")\n\n# Collect tuning metrics for each tuning process\ntune_metrics <- list(xgb = xgb_tune, lm = lm_tune) |>\n  map(collect_metrics)\n\n# Fit the models with the best parameters to the entire training data set\nfinal_wflows <- map2(\n  list(xgb = xgb_wflow, lm = lm_wflow),\n  best_models,\n  \\(x, y) finalize_workflow(x, y) |> fit(data = housing_train)\n)\n```\n:::\n\n\n### Model Evaluation\n\nWith the best performing models from cross-validation now fit to the entire training data set, I can evaluate these models against the test data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Evaluate each model with the test data and store 'last_fit' objects\nset.seed(485)\nfinal_wflow_evals <- map(\n  final_wflows,\n  \\(x) last_fit(\n    x,\n    split = housing_split,\n    metrics = metric_set(rmse, mae, mape, rsq_trad)\n  )\n)\n```\n:::\n\n\nNow I can see how each model performed on the test data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate a dataframe of model metrics to compare the two models\nmodel_metrics <- final_wflow_evals |>\n  map2_df(\n    names(final_wflow_evals),\n    ~ collect_metrics(.x) |> \n      select(.metric, .estimate) |> \n      pivot_wider(names_from = .metric, values_from = .estimate) |>\n      mutate(algorithm = .y) |>\n      relocate(algorithm)\n  )\n\nkable(model_metrics, booktabs = TRUE) |> kable_styling()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> algorithm </th>\n   <th style=\"text-align:right;\"> rmse </th>\n   <th style=\"text-align:right;\"> mae </th>\n   <th style=\"text-align:right;\"> mape </th>\n   <th style=\"text-align:right;\"> rsq_trad </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> xgb </td>\n   <td style=\"text-align:right;\"> 0.1365643 </td>\n   <td style=\"text-align:right;\"> 0.0954771 </td>\n   <td style=\"text-align:right;\"> 0.8758136 </td>\n   <td style=\"text-align:right;\"> 0.8525943 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lm </td>\n   <td style=\"text-align:right;\"> 0.1518358 </td>\n   <td style=\"text-align:right;\"> 0.1056075 </td>\n   <td style=\"text-align:right;\"> 0.9692341 </td>\n   <td style=\"text-align:right;\"> 0.8177832 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nIt looks like the XGB model outperformed the Linear Model on every metric, but not by very much. Both seem to have performed pretty well at predicting home sale prices. It's important to keep in mind here that the data were transformed, which is why the RMSE and MAE are so small. Now let's go ahead and open these \"black boxes\".\n\n## Opening the \"Black Box\"\n\n### Generate SHAP Values\n\nAs stated earlier, this part of the analysis will be based on SHAP values. [This explanation](https://christophm.github.io/interpretable-ml-book/shapley.html) from Christoph Molnar's book [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/) is a great primer on what SHAP values are and how they can help someone understand the effect of a given feature/variable on a prediction.\n\nWith that in mind, now that the models have been tuned, trained, and evaluated, I can generate SHAP values to understand what's going on under the hood (kinda). Note that this is still being run in parallel until the end of this portion.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get matrices of training features for each model\ntraining_features <- final_wflows |> \n  map(\\(x) pull_workflow_mold(x) |> pluck(\"predictors\"))\n\n# Register and set up the parallel backend\ncl <- parallel::makePSOCKcluster(parallel::detectCores(logical = FALSE) - 1)\ndoParallel::registerDoParallel(cl)\ninvisible(parallel::clusterEvalQ(cl, set.seed(44)))\n\nshap <- final_wflows |> map(get_shap)\n\n# Get SHAP variable importance features\nvar_imp <- shap |> map(get_shap_imp)\n\n# Close the connection to the cluster\nparallel::stopCluster(cl)\n```\n:::\n\n\n### Plot Relationships Between SHAP and the Training Data\n\nI now have my SHAP values and can begin to visualize a few different things. The first visualization will be a [SHAP summary plot](https://christophm.github.io/interpretable-ml-book/shap.html#shap-summary-plot), which I also found in Christoph Molnar's [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/). When I saw this plot I was amazed at how much information it actually contains once you grasp the dimensionality.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Pull data from the outermost point on the SHAP summary plot\npoint_dat_xgb <- get_shap_summary(\n  var_imp$xgb, \n  shap$xgb, \n  training_features$xgb, \n  max_features = 1\n) |>\n  mutate(shap_value = as.numeric(shap_value)) |>\n  slice_max(shap_value, with_ties = FALSE)\n\npoint_dat_lm <- get_shap_summary(\n  var_imp$lm, \n  shap$lm, \n  training_features$lm, \n  max_features = 1\n) |>\n  mutate(shap_value = as.numeric(shap_value)) |>\n  slice_max(shap_value, with_ties = FALSE)\n\n# Put the data from that point into a string object\npoint_annotation_xgb <- str_glue(\n  \"Row = {point_dat_xgb$id}\n  Variable = {point_dat_xgb$variable}\n  SHAP Value = {round(point_dat_xgb$shap_value, 3)}\n  Feature Value = {round(point_dat_xgb$feature_value, 3)}\"\n)\n\npoint_annotation_lm <- str_glue(\n  \"Row = {point_dat_lm$id}\n  Variable = {point_dat_lm$variable}\n  SHAP Value = {round(point_dat_lm$shap_value, 3)}\n  Feature Value = {round(point_dat_lm$feature_value, 3)}\"\n)\n\n# Create SHAP summaries containing data frames and plots\nshap_summary_plots <- list(\n  var_imp, \n  shap, \n  training_features\n) |>\n  pmap(get_shap_summary, max_features = 10) %>%\n  map2(c(\"XG Boost\", \"Linear Regression\"), plot_shap_summary)\n\ntotal_bsmt_sf_pdp <- final_wflows |>\n  map2(c(\"XG Boost\", \"Linear Regression\"), plot_pdp, pred_var = total_bsmt_sf)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate the SHAP summary plot with an annotation for the outermost point\nset.seed(23)\nshap_summary_plots$xgb + \n  geom_segment(\n    aes(x = 0.5, xend = 0.575, y = 8, yend = 10.01), \n    color = \"black\",\n    arrow = arrow(length = unit(0.03, \"npc\"))\n  ) +\n  annotate(\n    geom = \"text\", \n    x = 0.46, \n    y = 6.8, label = point_annotation_xgb, \n    hjust = \"center\"\n  )\n```\n\n::: {.cell-output-display}\n![](open-blackbox-tidy_files/figure-html/plot-shap-summary-xgb-1.png){width=1152}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate the SHAP summary plot with an annotation for the outermost point\nset.seed(23)\nshap_summary_plots$lm + \n  geom_segment(\n    aes(x = 0.79, xend = 0.9, y = 8, yend = 10), \n    color = \"black\",\n    arrow = arrow(length = unit(0.03, \"npc\"))\n  ) +\n  annotate(\n    geom = \"text\", \n    x = 0.8, \n    y = 6.8, label = point_annotation_lm, \n    hjust = \"center\"\n  )\n```\n\n::: {.cell-output-display}\n![](open-blackbox-tidy_files/figure-html/plot-shap-summary-lm-1.png){width=1152}\n:::\n:::\n\n\nThe first plot above shows that row 1693 has a positive SHAP value of 0.5879337 for the gr_liv_area (0.095) in the XGB model, which had an above average value of 4.1097005 in the training data. When considering all the observations collectively the feature value is ideally positively related with the SHAP value. Next I'll look at partial dependence plots to show the effect that the `gr_liv_area` has on `sale_price` according to each model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngr_liv_area_pdp <- final_wflows |>\n  map2(c(\"XG Boost\", \"Linear Regression\"), plot_pdp, pred_var = gr_liv_area)\n\ngr_liv_area_pdp$xgb\n```\n\n::: {.cell-output-display}\n![](open-blackbox-tidy_files/figure-html/pdp-plots-1.png){width=1152}\n:::\n\n```{.r .cell-code}\ngr_liv_area_pdp$lm\n```\n\n::: {.cell-output-display}\n![](open-blackbox-tidy_files/figure-html/pdp-plots-2.png){width=1152}\n:::\n:::\n\n\nAccording to both models the `gr_liv_area` variable positively effects the predicted sale price of a home in the training data, which seems consistent with general knowledge about home prices given that `gr_liv_area` is a measure of the above ground living area (more commonly known as \"square footage\"). It's important to note, however, that, unlike the coefficient in a regression model, one should not make inferences from a partial dependency beyond the dimensions of the training data. A partial dependency plot is meant only to provide an overview on the broad relationship between an explanatory variable and the target variable.\n\nLastly, I can look at how each feature affects a particular observation with a contribution plot. I'll consider the house observed in row 2049 of the training data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nobs_2409_contrib <- shap |>\n  map2(\n    c(\"XG Boost\", \"Linear Regression\"), \n    get_contributions, \n    rnum = 2049, \n    nfeat = 15 \n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nobs_2409_contrib$xgb$contrib_plot\n```\n\n::: {.cell-output-display}\n![](open-blackbox-tidy_files/figure-html/contrib-xgb-1.png){width=1152}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nobs_2409_contrib$lm$contrib_plot\n```\n\n::: {.cell-output-display}\n![](open-blackbox-tidy_files/figure-html/contrib-lm-1.png){width=1152}\n:::\n:::\n\n\nThe above XG Boost contribution plot shows that `total_bsmt_sf` had the largest positive effect on the predicted sale price of the sale in observation 2049 and having `garage_finish_Unf` (having an unfinished garage) had the largest negative effect. The Linear Regression contribution plot shows that `gr_liv_area` had the largest positive effect and `neighborhood_Brookside` had the largest negative effect on the predicted sale price. However, it's interesting to note that `garage_finish_Fin`, the opposite of `garage_finish_Unf`, had a negative effect in the Linear Regression.\n\n## Final Thoughts\n\nWhile these methods of looking into machine learning algorithms are not designed for inference, they do go a long way in helping to elucidate the relationships or patterns that machine learning algorithms find. They help answer the questions about why some predictions come out the way that they do, whether they make sense or not.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}