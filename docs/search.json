[
  {
    "objectID": "cepumd-intro.html",
    "href": "cepumd-intro.html",
    "title": "Introduction to cepumd",
    "section": "",
    "text": "The purpose of cepumd is to make working with Consumer Expenditure Surveys (CE) Public-Use Microdata (PUMD) easier toward calculating mean, weighted, annual expenditures (henceforth “mean expenditures”). The challenges cepumd seeks to address deal primarily with pulling together the necessary data toward this end. Some of the overarching ideas underlying the package are as follows:\n\nUse a Tidyverse framework for most operations and be (hopefully) generally Tidyverse friendly\nBalance the effort to make the end user’s experience with CE PUMD easier while being flexible enough to allow that user to perform any analysis with the data they wish\nOnly designed to help users calculate mean expenditures on and of the consumer unit (CU), i.e., not income, not assets, not liabilities, not gifts, at least for now"
  },
  {
    "objectID": "cepumd-intro.html#motivation",
    "href": "cepumd-intro.html#motivation",
    "title": "Introduction to cepumd",
    "section": "",
    "text": "The purpose of cepumd is to make working with Consumer Expenditure Surveys (CE) Public-Use Microdata (PUMD) easier toward calculating mean, weighted, annual expenditures (henceforth “mean expenditures”). The challenges cepumd seeks to address deal primarily with pulling together the necessary data toward this end. Some of the overarching ideas underlying the package are as follows:\n\nUse a Tidyverse framework for most operations and be (hopefully) generally Tidyverse friendly\nBalance the effort to make the end user’s experience with CE PUMD easier while being flexible enough to allow that user to perform any analysis with the data they wish\nOnly designed to help users calculate mean expenditures on and of the consumer unit (CU), i.e., not income, not assets, not liabilities, not gifts, at least for now"
  },
  {
    "objectID": "cepumd-intro.html#history-of-ce",
    "href": "cepumd-intro.html#history-of-ce",
    "title": "Introduction to cepumd",
    "section": "History of CE",
    "text": "History of CE\nFirst a little history…\nThe first Consumer Expenditure Survey happened in 1888 (https://www.bls.gov/opub/hom/cex/history.htm), it was first used to revise CPI weights in 1972-1973, and it has been collected on a monthly basis since 1979. For a little bit more detail on the history of the CE, check out the slide deck of a presentation delivered by Steve Henderson (former Chief of the Branch of Information and Analysis) and Adam Safir (current Division Chief of CE) called 130 Years of theConsumer Expenditure Surveys (CE): 1888 - 2018"
  },
  {
    "objectID": "cepumd-intro.html#overview-of-the-ce-and-ce-pumd",
    "href": "cepumd-intro.html#overview-of-the-ce-and-ce-pumd",
    "title": "Introduction to cepumd",
    "section": "Overview of the CE and CE PUMD",
    "text": "Overview of the CE and CE PUMD\nFrom the CE home page:\n\n“The Consumer Expenditure Surveys (CE) program provides data on expenditures, income, and demographic characteristics of consumers in the United States. The CE program provides these data in tables, LABSTAT database, news releases, reports, and public use microdata files.\n\n\nCE data are collected by the Census Bureau for BLS in two surveys, the Interview Survey for major and/or recurring items and the Diary Survey for more minor or frequently purchased items. CE data are primarily used to revise the relative importance of goods and services in the market basket of the Consumer Price Index. The CE is the only Federal household survey to provide information on the complete range of consumers’ expenditures and incomes. Here is an overview of the CE program and its methods.”\n\nSome important things to note are that expenditure data are collected through two different survey instruments (Diary and Interview), expenditure categories are organized hierarchichally, and data are stored across thousands of files to which the CE provides access through their website. Also, given the length of the program, it would be difficult to harmonize data across all those years and files, so there are some inconsistencies in the way data are stored, which cepumd seeks to address (more on this further down).\nPlease visit the following pages to learn more about the CE program overall and CE PUMD more specifically.\n\nCE homepage: (https://www.bls.gov/cex/)\nCE PUMD page: (https://www.bls.gov/cex/pumd.htm)\nCE PUMD Getting Started Guide: https://www.bls.gov/cex/pumd-getting-started-guide.htm\nCE Dictionary for Interview and Diary Surveys (XLSX download) (https://www.bls.gov/cex/pumd/ce_pumd_interview_diary_dictionary.xlsx)\nCE PUMD published tables: (https://www.bls.gov/cex/tables.htm)\nCE PUMD Handbook of Methods: https://www.bls.gov/opub/hom/cex/\nCE Frequently Asked Questions: https://www.bls.gov/cex/csxfaqs.htm"
  },
  {
    "objectID": "cepumd-intro.html#challenges-addressed-by-cepumd",
    "href": "cepumd-intro.html#challenges-addressed-by-cepumd",
    "title": "Introduction to cepumd",
    "section": "Challenges addressed by cepumd",
    "text": "Challenges addressed by cepumd\ncepumd seeks to address challenges in three categories: data gathering/organization; managing data inconsistencies; and calculating weighted, annual metrics.\n\nData gathering/organization\n\nConvert hierarchical grouping (HG) files to data tables using ce_hg()\nHelp the user identify the Universal Classification Codes (UCCs) related to their analysis using a combination of ce_hg() and ce_uccs()\nCombine all required files and variables using ce_prepdata()\n\nManaging data inconsistencies\n\nProvide the ability to recode variable categories using the CE Dictionary for Interview and Diary Surveys\nResolve some inconsistencies such as differences code definitions between the Interview and Diary (check the definitions of the “FAM_TYPE” variable categories in 2015 for an example)\nProvide useful errors or warnings when there are multiple categories of something the user is trying to access, e.g., some titles in the hierarchical grouping files (“stub” or “HG” files) repeat and requires more careful selection of UCCs\n\nCalculating weighted, annual metrics\n\nCalculate a mean expenditure with ce_mean() or expenditure quantile with ce_quantile()\nAccount for the factor (annual vs. quarterly expenditure)\nAccount for the “months in scope” of a given consumer unit (CU)\nAnnualize expenditures for either Diary or Interview expenditures\nIntegrate Interview and Diary data as necessary\n\n\nSource code and other package information is available at https://github.com/arcenis-r/cepumd"
  },
  {
    "objectID": "cepumd-intro.html#cautions-and-recommendations",
    "href": "cepumd-intro.html#cautions-and-recommendations",
    "title": "Introduction to cepumd",
    "section": "Cautions and recommendations",
    "text": "Cautions and recommendations\n\nEstimates produced using PUMD, which is topcoded by the CE and has some records suppressed to protect respondent confidentiality, will not match the published estimates released by the CE in most cases. The CE’s published estimates are based on confidential data that are not topcoded nor have records suppressed. You can learn more at CE Protection of Respondent Confidentiality.\nWhen calculating estimates for sub-samples or crosss-sections of data it is best to stick to the combinations of variables that the CE uses in it’s publication tables, e.g., income, geography, composition of CU, size of CU. This is because CE data are collected using a stratified, random sample (a.k.a., “representative sample”) and only analyses conducted using the stratification variables are statistically valid. Using other variables can be helpful to understand spending across different groups, but unweighted estimates are likely more useful for this. cepumd currently does not support unweighted estimates, but data for such an analysis can be prepared using ce_prepdata().\nQuantiles should only be generated using data from 1 survey instrument as the samples for the Interview and Diary are different.\nCheck the expenditure category in the appropriate HG file to ensure that it is the category for which you intend to generate an estimate.\nStore an HG object in the environment and call that directly in ce_prepdata()."
  },
  {
    "objectID": "cepumd-intro.html#installation",
    "href": "cepumd-intro.html#installation",
    "title": "Introduction to cepumd",
    "section": "Installation",
    "text": "Installation\nYou can install the development version of cepumd from its GitHub repo.\n\npak::pkg_install(\"arcenis-r/cepumd\")"
  },
  {
    "objectID": "cepumd-intro.html#key-cepumd-functions",
    "href": "cepumd-intro.html#key-cepumd-functions",
    "title": "Introduction to cepumd",
    "section": "Key cepumd functions",
    "text": "Key cepumd functions\n\nThe workhorse of cepumd is ce_prepdata(). It merges the household characteristics file (FMLI/-D) with the corresponding expenditure tabulation file (MTBI/EXPD) for a specified year, adjusts weights for months-in-scope and the number of collection quarters, adjusts some cost values by their periodicity factor (some cost categories are represented as annual figures and others as quarterly). With the recent update it only requires the first 3 arguments to function: the year, the survey type, and one or more valid UCCs. ce_prepdata() now creates all of the other necessary objects within the function if not provided.\nThere are two functions for wrangling hierarchical grouping data into more useable formats:\n\nce_hg() pulls the requested type of HG file (Interview, Diary, or Integrated) for a specified year.\nce_uccs() filters the HG file for the specified expenditure category and returns either a data frame with only that section of the HG file or the Universal Classification Codes (UCCs) that make up that expenditure category.\n\nThere are two functions that the user can use to calculate CE summary statistics:\n\nce_mean() calculates a mean expenditure, standard error of the mean, coefficient of variation, and an aggregate expenditure.\nce_quantiles() calculates weighted expenditure quantiles. It is important to note that calculating medians for integrated expenditures is not recommended because the calculation involves using weights from both the Diary and Survey instruments."
  },
  {
    "objectID": "cepumd-intro.html#example-workflows",
    "href": "cepumd-intro.html#example-workflows",
    "title": "Introduction to cepumd",
    "section": "Example workflows",
    "text": "Example workflows\nThe following are a few sample workflows that show how cepumd can be used. Before jumping into those I’ll first install and load the necessary pacakges and store some CEPUMD files. I’ll keep the path to those files in a variable called ce_data_dir.\n\npacman::p_load(knitr, readxl, tidyverse, cepumd)\n\n\nSimple workflow: Integrated pet expenditures\nThe following is an example of how someone might go about using cepumd to calculate a 2021 annual, weighted estimate of mean expenditures on pets for all of the U.S. using CE integrated data. This is just a quick and easy calculation.\n\ninteg21_hg &lt;- ce_hg(\n  2021,\n  integrated,\n  hg_zip_path = file.path(ce_data_dir, \"stubs.zip\")\n)\n\nce_prepdata(\n  2021,\n  integrated,\n  integ21_hg,\n  uccs = ce_uccs(integ21_hg, expenditure = \"Pets\", ucc_group = \"PETS\"),\n  dia_zp = file.path(ce_data_dir, \"diary21.zip\"),\n  int_zp = c(\n    file.path(ce_data_dir, \"intrvw20.zip\"),\n    file.path(ce_data_dir, \"intrvw21.zip\")\n  )\n) |&gt;\n  ce_mean() |&gt;\n  kable(booktabs = TRUE)\n\n\n\n\nagg_exp\nmean_exp\nse\ncv\n\n\n\n\n130886736176\n981.3035\n53.5767\n5.459748\n\n\n\n\n\nYup… that’s all it takes. I simply ran ce_hg to get the hierarchical grouping (stub) file for integrated expenditures for 2021; then ran ce_prepdata() with the year, the survey type, the stub file, uccs I needed, and the file paths to where I downloaded the data files; then I piped that directly into ce_mean(). An important thing to notice is that I provided two file paths to the int_zp argument. I did this because calculating integrated CE annual estimates actually requires 5 quarters of data from the Interview survey. Some of the data for calculating 2021 estimates is provided in the 2020 Interview data.This is one of the reasons it’s important to be familiar with CE methodology and how it changes over time when working with CE PUMD. Prior to 2020, file storing practices were different as stated in the Getting Started Guide Interview Survey section.\n\n\nSlightly more advanced workflow: Used Car & Truck Expenditures by Urbanicity\nIn this example I’ll calculate estimated annual expenditures on new and used cars by urbanicity also for 2021. Once the data are prepped with ce_data() I’ll just nest the data by urbanicity and run ce_means() and ce_quantiles() on the nested datasets. Since the overwhelming number of reports of vehicle purchases occur in the Interview survey, I’ll only use Interview data.\nFirst I’ll get the stub file and filter it for categories involving new or used cars.\n\nint21_hg &lt;- ce_hg(\n  2021,\n  interview,\n  hg_zip_path = file.path(ce_data_dir, \"stubs.zip\")\n)\n\nint21_hg |&gt;\n  filter(str_detect(title, \"[C|c]ars\")) |&gt;\n  kable(booktabs = TRUE)\n\n\n\n\nlevel\ntitle\nucc\nsurvey\nfactor\n\n\n\n\n4\nCars and trucks, new\nNEWCARS\nG\n1\n\n\n5\nNew cars\n450110\nI\n1\n\n\n4\nCars and trucks, used\nUSEDCARS\nG\n1\n\n\n5\nUsed cars\n460110\nI\n1\n\n\n\n\n\nSo there’s one UCC for “New cars” and one for “Used cars”. I’ll use the code above to grab those UCCs and prepare my data.\n\ncar_data &lt;- ce_prepdata(\n  2021,\n  interview,\n  int21_hg,\n  uccs = int21_hg |&gt;\n    filter(str_detect(title, \"[C|c]ars\"), !is.na(as.numeric(ucc))) |&gt;\n    pull(ucc),\n  bls_urbn,  # &lt;------- this is the variable for urbanicity\n  int_zp = c(\n    file.path(ce_data_dir, \"intrvw20.zip\"),\n    file.path(ce_data_dir, \"intrvw21.zip\")\n  ),\n  recode_variables = TRUE,\n  dict_path = file.path(ce_data_dir, \"ce-data-dict.xlsx\")\n)\n\ncar_data |&gt;\n  group_nest(bls_urbn) |&gt;\n  mutate(ce_ann_means = map(data, ce_mean)) |&gt;\n  select(-data) |&gt;\n  unnest(ce_ann_means) |&gt;\n  kable(booktabs = TRUE)\n\n\n\n\nbls_urbn\nagg_exp\nmean_exp\nse\ncv\n\n\n\n\nUrban\n168458799558\n1341.7184\n106.2495\n7.918912\n\n\nRural\n4756065697\n591.5108\n155.0020\n26.204421\n\n\n\n\n\nGetting the annual, weighted estimate of the median (or another quantile) would be just as easy. Since I’m using interview data only here (it would be bad practice to try to calculate quantiles with integrated data), this would be a good example. I’ll calculate the first percentile and the median along with the 0.991 through 0.999 quantiles for the overall sample rather than breaking it down by urbanicity.\n\nce_quantiles(\n  car_data,\n  probs = c(0.01, 0.5, 0.95, seq(0.99, 0.999, by = 0.001))\n) |&gt;\n  kable(booktabs = TRUE)\n\n\n\n\nprobs\nquantile\n\n\n\n\n1.0%\n0\n\n\n50.0%\n0\n\n\n95.0%\n0\n\n\n99.0%\n8300\n\n\n99.1%\n10000\n\n\n99.2%\n12434\n\n\n99.3%\n15000\n\n\n99.4%\n17850\n\n\n99.5%\n20000\n\n\n99.6%\n22948\n\n\n99.7%\n26593\n\n\n99.8%\n30000\n\n\n99.9%\n40000\n\n\n\n\n\nAt least 95% of households in the Interview survey did not report expenditures on cars in 2021, which explains why the mean is so low.\n\n\nVery advanced workflow: Inflation adjusted food away from home expenditures by household size\nIn this last example I’m going to assume very little knowledge about the CE. I’d like to compare mean annual expenditures on food away from home between 2010 and 2020 by household size and I want to convert expenditures to 2023 dollars using the CPI. First I’d go to the CE PUMD Data Files page and download the files that I need for both years. I’ll also go to the CE PUMD Documentation page to download the hierarchical grouping files to get the UCCs for “Food away from home” and the CE Dictionary to find out what variable has data on the household size.\nWith all that done, now I want to look at the hierarchical grouping files for 2010 and 2020 for integrated data as they relate to “Food away from home”.\n\ninteg10_hg &lt;- ce_hg(\n  2010,\n  integrated,\n  hg_zip_path = file.path(ce_data_dir, \"stubs.zip\")\n)\n\ninteg20_hg &lt;- ce_hg(\n  2020,\n  integrated,\n  hg_zip_path = file.path(ce_data_dir, \"stubs.zip\")\n)\n\nFirst I’ll explore the titles of the hierarchical grouping files to see if any of them mention “food away”\n\ninteg10_hg |&gt;\n  filter(str_detect(str_to_lower(title), \"food away\")) |&gt;\n  kable(booktabs = TRUE)\n\n\n\n\nlevel\ntitle\nucc\nsurvey\nfactor\n\n\n\n\n3\nFood away from home\nFOODAWAY\nG\n1\n\n\n\n\n\nNow I’ll do the same for 2020.\n\ninteg20_hg |&gt;\n  filter(str_detect(str_to_lower(title), \"food away\")) |&gt;\n  kable(booktabs = TRUE)\n\n\n\n\nlevel\ntitle\nucc\nsurvey\nfactor\n\n\n\n\n3\nFood away from home\nFOODAW\nG\n1\n\n\n\n\n\nHere I’ll take note of the title, which is the same in both years (“Food away from home”). I’ll use that to get the UCCs for both years.\n\nfood_away_uccs_10 &lt;- integ10_hg |&gt;\n  ce_uccs(expenditure = \"Food away from home\")\n\nfood_away_uccs_20 &lt;- integ20_hg |&gt;\n  ce_uccs(expenditure = \"Food away from home\")\n\nHere’s a quick look at the UCCs from 2010.\n\nfood_away_uccs_10\n\n [1] \"190111\" \"190112\" \"190113\" \"190114\" \"190211\" \"190212\" \"190213\" \"190214\"\n [9] \"190311\" \"190312\" \"190313\" \"190314\" \"190321\" \"190322\" \"190323\" \"190324\"\n[17] \"190901\" \"190902\" \"190903\" \"790430\" \"800700\"\n\n\nNow the 2020 UCCs.\n\nfood_away_uccs_10\n\n [1] \"190111\" \"190112\" \"190113\" \"190114\" \"190211\" \"190212\" \"190213\" \"190214\"\n [9] \"190311\" \"190312\" \"190313\" \"190314\" \"190321\" \"190322\" \"190323\" \"190324\"\n[17] \"190901\" \"190902\" \"190903\" \"790430\" \"800700\"\n\n\nThe vectors of UCCs look identical, but I’ll keep both just to be cautious.\nNext I’ll turn to finding the variable for household size in the CE data dictionary. It’s important to remember that the dictionary is stored as an “XLSX” file. I’ll use functions from the readxl package to work with the dictionary.\n\nexcel_sheets(file.path(ce_data_dir, \"ce-data-dict.xlsx\"))\n\n[1] \"Cover\"     \"Variables\" \"Codes \"   \n\n\nNow I’ll see what variables contain anything about the number of household members. To do that I’ll have to load the sheet from the dictionary containing the variable definitions. I also want to filter the variable data to only the FMLI where the “Last year” column is missing, i.e., the variable definition is still in use.\n\nce_variables &lt;- read_excel(\n  file.path(ce_data_dir, \"ce-data-dict.xlsx\"),\n  sheet = \"Variables\"\n)\n\nce_variables |&gt;\n  filter(\n    str_detect(File, \"FMLI\"),\n    str_detect(\n      tolower(`Variable description`), \"number of members\"\n    )\n  ) |&gt;\n  kable(booktabs = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSurvey\nFile\nVariable Name\nVariable description\nFormula\nFlag name\nSection number\nSection description\nSection part\nFirst year\nFirst Quarter\nLast quarter\nLast year\nComment\n\n\n\n\nINTERVIEW\nFMLI\nAS_COMP5\nNumber of members under age 2 in CU\nCOUNT (AGE &lt; 2)\nAS_C_MP5\nNA\nCU characteristics, income, weights, and summary level expenditures.\nNA\n1984\n1\nNA\nNA\nNA\n\n\nINTERVIEW\nFMLI\nAS_COMP5\nNumber of members under age 2 in CU\nNA\nAS_C_MP5\nNA\nCU characteristics, income, weights, and summary level expenditures.\nNA\n1980\n1\n4\n1981\nNA\n\n\nINTERVIEW\nFMLI\nFAM_SIZE\nNumber of Members in CU\nNA\nFAM__IZE\nNA\nCU characteristics, income, weights, and summary level expenditures.\nNA\n1984\n1\nNA\nNA\nNA\n\n\nINTERVIEW\nFMLI\nFAM_SIZE\nNumber of Members in CU\nNA\nFAM__IZE\nNA\nCU characteristics, income, weights, and summary level expenditures.\nNA\n1980\n1\n4\n1981\nNA\n\n\n\n\n\nIt looks like FAM_SIZE is the variable I want. I can see that this variable was used from 1980 through 1981 then was dropped and re-introduced in 1984 and has been in use since. So it looks like it’s available for my 2 years of interest. Next I’ll check whether the FAM_SIZE variable has any value codes associated with it. I’ll have to pull in the “Codes” sheet. (Check your spelling here.)\n\nce_codes &lt;- read_excel(\n  file.path(ce_data_dir, \"ce-data-dict.xlsx\"),\n  sheet = \"Codes \"\n)\n\nce_codes |&gt;\n  filter(File %in% \"FMLI\", Variable %in% \"FAM_SIZE\") |&gt;\n  kable(booktabs = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSurvey\nFile\nVariable\nCode value\nCode description\nFirst year\nFirst quarter\nLast year\nLast quarter\nComment\n…11\n\n\n\n\n\n\n\nIt looks like FAM_SIZE is not a coded variable (no observations in the “Codes” sheet), so it must be numeric. With all that, I’m ready to prepare my data. I’ll start by preparing the 2010 data and getting a summary of the FAM_SIZE variable since it is a continuous variable.\n\nfood_away_data_10 &lt;- ce_prepdata(\n  2010,\n  integrated,\n  integ10_hg,\n  food_away_uccs_10,\n  dia_zp = file.path(ce_data_dir, \"diary10.zip\"),\n  int_zp = file.path(ce_data_dir, \"intrvw10.zip\"),\n  fam_size\n)\n\nsummary(food_away_data_10$fam_size)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   1.000   2.000   2.666   4.000  14.000 \n\n\nSince some households have as many as 14 people, I’ll create a FAM_SIZE label with any number greater than 4 taking on the value “5+”. Next, I’ll prepare the 2020 data and rowbind it with the 2010 data as well as create the “fam_size_label” variable. I’m also going to convert “ref_mo” and “ref_yr” to character to make it compatible with the CPI data that I’ll get later. I’ll also take a look at just a snippet of the data.\n\nfood_away_data_20 &lt;- ce_prepdata(\n  2020,\n  integrated,\n  integ10_hg,\n  food_away_uccs_20,\n  dia_zp = file.path(ce_data_dir, \"diary20.zip\"),\n  int_zp = c(\n    file.path(ce_data_dir, \"intrvw19.zip\"),\n    file.path(ce_data_dir, \"intrvw20.zip\")\n  ),\n  fam_size\n)\n\nfood_away_comp_data &lt;- food_away_data_10 |&gt;\n  mutate(year = \"2010\") |&gt;\n  bind_rows(food_away_data_20 |&gt; mutate(year = \"2020\")) |&gt;\n  mutate(\n    fam_size_label = if_else(fam_size &gt; 4, \"5+\", as.character(fam_size)),\n    ref_yr = as.character(ref_yr)\n  )\n\nfood_away_comp_data |&gt;\n  select(survey, year, newid, finlwt21, cost, ucc, ref_yr, ref_mo) |&gt;\n  filter(!is.na(ucc)) |&gt;\n  group_by(year, survey) |&gt;\n  slice_sample(n = 3) |&gt;\n  ungroup() |&gt;\n  kable(booktabs = TRUE)\n\n\n\n\nsurvey\nyear\nnewid\nfinlwt21\ncost\nucc\nref_yr\nref_mo\n\n\n\n\nD\n2010\n01077131\n30223.681\n99.5800\n190111\n2010\n5\n\n\nD\n2010\n01064582\n32967.621\n585.0000\n190312\n2010\n4\n\n\nD\n2010\n01101342\n3212.632\n156.0000\n190113\n2010\n7\n\n\nI\n2010\n02033974\n31851.886\n115.0000\n190902\n2010\n1\n\n\nI\n2010\n02202594\n16407.329\n100.0000\n190903\n2010\n4\n\n\nI\n2010\n02273203\n15055.666\n80.0000\n190903\n2010\n9\n\n\nD\n2020\n04457441\n49062.106\n162.8900\n190111\n2020\n3\n\n\nD\n2020\n04368522\n19837.453\n355.6381\n190312\n2020\n2\n\n\nD\n2020\n04371472\n67164.988\n116.8700\n190313\n2020\n2\n\n\nI\n2020\n04419662\n28994.808\n250.0000\n190903\n2020\n8\n\n\nI\n2020\n04234723\n30158.950\n10.0000\n190903\n2020\n1\n\n\nI\n2020\n04392893\n39264.329\n240.0000\n190903\n2020\n10\n\n\n\n\n\nI’ll now get CPI data for the years in the analysis and for 2023 to set as a base using the blsR package (https://github.com/groditi/blsR). I’m going to use the “All Urban Consumers (Current Series)” series, which has series ID “CUUR0000SA0”.\n\ncpi_data &lt;- blsR::get_series(\n  \"CUUR0000SA0\",\n  start_year = 2010,\n  end_year = 2023\n) |&gt;\n  pluck(\"data\") |&gt;\n  map(\n    \\(x) list_flatten(x) |&gt;\n      enframe() |&gt;\n      filter(!name %in% \"footnotes\") |&gt;\n      unnest(value) |&gt;\n      pivot_wider(values_from = value, names_from = name)\n  ) |&gt;\n  list_rbind() |&gt;\n  rename(cpi = \"value\") |&gt;\n  mutate(month = match(periodName, month.name))\n\ncpi_base &lt;- cpi_data |&gt; filter(year %in% \"2023\", month %in% \"12\")\n\ncpi_data &lt;- cpi_data |&gt; filter(year %in% unique(food_away_comp_data$ref_yr))\n\ncpi_data |&gt; slice(1:10) |&gt; kable(booktabs = TRUE)\n\n\n\n\nyear\nperiod\nperiodName\ncpi\nmonth\n\n\n\n\n2021\nM12\nDecember\n278.802\n12\n\n\n2021\nM11\nNovember\n277.948\n11\n\n\n2021\nM10\nOctober\n276.589\n10\n\n\n2021\nM09\nSeptember\n274.310\n9\n\n\n2021\nM08\nAugust\n273.567\n8\n\n\n2021\nM07\nJuly\n273.003\n7\n\n\n2021\nM06\nJune\n271.696\n6\n\n\n2021\nM05\nMay\n269.195\n5\n\n\n2021\nM04\nApril\n267.054\n4\n\n\n2021\nM03\nMarch\n264.877\n3\n\n\n\n\n\nThe base that I’m going to covert to is December 2023.\n\ncpi_base |&gt; kable(booktabs = TRUE)\n\n\n\n\nyear\nperiod\nperiodName\ncpi\nmonth\n\n\n\n\n2023\nM12\nDecember\n306.746\n12\n\n\n\n\n\nNext I’m going to join the CPI data to the CE data and adjust the “cost” variable for inflation. Note that I replace resulting missing values in the “cost” variable with “0”. Missing values will result when I multiply a cost of “0” by an adjustment factor and ce_mean() will not function with missing values.\n\nfood_away_comp_data &lt;- food_away_comp_data |&gt;\n  left_join(\n    select(cpi_data, year, month, cpi),\n    by = c(\"ref_yr\" = \"year\", \"ref_mo\" = \"month\")\n  ) |&gt;\n  mutate(\n    base_cpi = pull(cpi_base, cpi),\n    across(c(base_cpi, cpi), as.numeric),\n    cost = cost * (base_cpi / cpi) |&gt; replace_na(0)\n  )\n\nfood_away_comp_data |&gt;\n  select(survey, year, newid, finlwt21, cost, ucc, ref_yr, ref_mo) |&gt;\n  filter(!is.na(ucc)) |&gt;\n  group_by(year, survey) |&gt;\n  slice_sample(n = 3) |&gt;\n  ungroup() |&gt;\n  kable(booktabs = TRUE)\n\n\n\n\nsurvey\nyear\nnewid\nfinlwt21\ncost\nucc\nref_yr\nref_mo\n\n\n\n\nD\n2010\n01056592\n29120.603\n2707.22021\n190212\n2010\n3\n\n\nD\n2010\n01106842\n40769.742\n415.55265\n190311\n2010\n8\n\n\nD\n2010\n01067682\n25803.616\n458.08019\n190212\n2010\n3\n\n\nI\n2010\n02171745\n12427.410\n351.75519\n190903\n2010\n7\n\n\nI\n2010\n02201685\n15472.987\n140.50808\n190903\n2010\n8\n\n\nI\n2010\n02295565\n13314.490\n93.30152\n790430\n2010\n12\n\n\nD\n2020\n04517642\n27413.448\n456.92667\n190211\n2020\n6\n\n\nD\n2020\n04440151\n43330.546\n289.04405\n190311\n2020\n2\n\n\nD\n2020\n04516122\n89157.335\n1185.06971\n190212\n2020\n7\n\n\nI\n2020\n04267823\n20258.845\n24.97050\n790430\n2020\n1\n\n\nI\n2020\n04416314\n9413.094\n235.52907\n190903\n2020\n12\n\n\nI\n2020\n04386873\n15345.161\n1192.42055\n800700\n2020\n4\n\n\n\n\n\nThe next step is to calculate means, for which I’ll use some more Tidyverse functions.\n\nfood_away_means &lt;- food_away_comp_data |&gt;\n  group_nest(year, fam_size_label, .key = \"data\") |&gt;\n  mutate(ce_mn_df = map(data, ce_mean)) |&gt;\n  select(-data) |&gt; \n  unnest(ce_mn_df) |&gt;\n  mutate(lower = mean_exp - cv, upper = mean_exp + cv)\n\nfood_away_means |&gt; kable(booktabs = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyear\nfam_size_label\nagg_exp\nmean_exp\nse\ncv\nlower\nupper\n\n\n\n\n2010\n1\n77335813000\n2207.926\n87.23315\n3.950909\n2203.975\n2211.877\n\n\n2010\n2\n137538943234\n3479.533\n102.54849\n2.947192\n3476.585\n3482.480\n\n\n2010\n3\n70833802054\n4028.171\n187.60152\n4.657238\n4023.514\n4032.829\n\n\n2010\n4\n78621552689\n4994.423\n196.31421\n3.930669\n4990.492\n4998.354\n\n\n2010\n5+\n60764779535\n4668.419\n252.13159\n5.400792\n4663.018\n4673.820\n\n\n2020\n1\n67173826416\n1713.043\n84.53129\n4.934569\n1708.108\n1717.977\n\n\n2020\n2\n122787510310\n2825.619\n131.55436\n4.655771\n2820.963\n2830.275\n\n\n2020\n3\n61184160903\n3170.855\n203.25085\n6.409971\n3164.445\n3177.265\n\n\n2020\n4\n68948170493\n4210.973\n262.49920\n6.233695\n4204.739\n4217.206\n\n\n2020\n5+\n48767026459\n3737.376\n327.18302\n8.754351\n3728.622\n3746.130\n\n\n\n\n\nPlotting these data would be pretty straightforward, as well.\n\nfood_away_means |&gt;\n  ggplot(aes(x = fam_size_label, y = mean_exp, fill = year, group = year)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", width = 0.8) +\n  geom_errorbar(\n    aes(ymin = lower, ymax = upper),\n    width = 0.4,\n    position = position_dodge(0.75)\n  ) +\n  scale_fill_manual(values = c(\"red\", \"blue\")) +\n  scale_y_continuous(labels = scales::dollar) +\n  labs(\n    title =\n      \"Estimated annual mean food away from home expenditures by CU size\",\n    x = \"CU size\",\n    y = \"Estimated, weighted, annual mean expenditure\",\n    fill = \"Year\"\n  ) +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"bottom\")\n\n\n\n\nHere we can see that on an inflation-adjusted basis, households of all sizes had higher expenditures on food away from home in 2010 than they did in 2020.\nNow I’ll generate a plot of the expenditures at each weighted, annual, estimated quantile (from 0.01 through 0.99, by 0.01) for the same years, but only using Diary data, since most of the UCCs (16 out of 21) in the “food away from home” category come from the Diary.\n\nfood_away_comp_quantiles &lt;- map2(\n  c(2010, 2020),\n  c(\n    file.path(ce_data_dir, \"diary10.zip\"),\n    file.path(ce_data_dir, \"diary20.zip\")\n  ),\n  \\(x, y) {\n    dia_hg &lt;- ce_hg(\n      x,\n      diary,\n      hg_zip_path = file.path(ce_data_dir, \"stubs.zip\")\n    )\n    \n    food_uccs &lt;- ce_uccs(dia_hg, expenditure = \"Food away from home\")\n    \n    ce_prepdata(\n      x,\n      diary,\n      dia_hg,\n      food_uccs,\n      dia_zp = y\n    ) |&gt;\n      mutate(year = x, ref_yr = as.character(ref_yr))\n  }\n) |&gt;\n  list_rbind() |&gt;\n  left_join(\n    select(cpi_data, year, month, cpi),\n    by = c(\"ref_yr\" = \"year\", \"ref_mo\" = \"month\")\n  ) |&gt;\n  mutate(year = factor(year)) |&gt;\n  nest(data = -year) |&gt;\n  mutate(\n    fa_qtile = map(data, ce_quantiles, probs = c(seq(0, 0.95, by = 0.05), 0.99))\n  ) |&gt;\n  select(-data) |&gt;\n  unnest(fa_qtile) |&gt;\n  mutate(probs = parse_number(probs) / 100)\n\nfood_away_comp_quantiles |&gt;\n  ggplot(aes(x = probs, y = quantile, group = year, color = year)) +\n  geom_line() +\n  scale_color_manual(values = c(\"red\", \"blue\")) +\n  scale_x_continuous(labels = scales::percent) +\n  scale_y_continuous(labels = scales::dollar) +\n  labs(\n    title =\n      \"Estimated, annual food away from home expenditure quantiles\",\n    x = \"Quantile\",\n    y = \"Estimated, weighted, annual expenditure\",\n    color = \"Year\"\n  ) +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"bottom\")\n\n\n\n\nInterestingly the expenditures don’t appear to have changed much between 2010 and 2020 across quantiles on an inflation-adjusted basis, but we can see that across all quantiles, CU’s spent less in 2020 than they did in 2010 on food away from home, which is consistent with the means that we calculated above. There are a lot of 0-value reported expenditures, though, in the CE on food away from home. Unfortunately, I can’t perform an analysis using only respondents that did have expenditures in this category, i.e., dropping the 0’s, because whether someone had an expenditure on food away from home is not one of the variables used for generating the survey weights. In other words, the analysis can be done, but it would not be statistically valid and I definitely wouldn’t be able to infer from it. This is just another cautionary note to anyone using this package who might use it in a way that does not follow statistically sound practices. Please visit the CE’s website and read the CE PUMD Getting Started Guide for more information.\n\n\nDealing with inconsistent code definitions\nIn this workflow I’m going to calculate estimated mean utilities expenditures for 2015 using integrated data by CU composition using the FAM_TYPE variable. In this case I’m going to start by looking at the codes for that variable to show how one might run into an inconsistency in code definitions across survey instruments. First I’m going to set up a sub-directory in my temporary directory and store what I’ll need to get started.\nFirst, I’ll look at code descriptions for the “FAM_TYPE” variable in the dictionary and I’m going to focus on the code values of 3, 5, and 7. I still have the ce_codes object in memory, so I’ll just use that.\n\nce_codes |&gt;\n  janitor::clean_names() |&gt;\n  filter(\n    variable %in% \"FAM_TYPE\",\n  first_year &lt;= 2015,\n  (last_year &gt;= 2015 | is.na(last_year)),\n  code_value %in% c(\"3\", \"5\", \"7\")\n  ) |&gt;\n  select(survey, code_value, code_description) |&gt;\n  arrange(code_value, survey) |&gt;\n  kable(booktabs = TRUE)\n\n\n\n\n\n\n\n\n\nsurvey\ncode_value\ncode_description\n\n\n\n\nDIARY\n3\nMarried couple, own children only, oldest child &gt; 6, &lt; 18\n\n\nINTERVIEW\n3\nMarried Couple, own children only oldest child &gt;= 6, &lt;= 17\n\n\nDIARY\n5\nAll other Married couple families\n\n\nINTERVIEW\n5\nAll other Husband and wife families\n\n\nDIARY\n7\nOne parent, female, own children, at least one age &lt; 18\n\n\nINTERVIEW\n7\nOne parent, female, own children, at least one age &lt; 18\n\n\n\n\n\nThe code descriptions for these 3 code values are different across instruments. To resolve this I’m going to create a table containing only codes from the Interview survey.\n\nfam_type_codes &lt;- ce_codes |&gt;\n  janitor::clean_names() |&gt;\n  filter(\n    variable %in% \"FAM_TYPE\",\n    first_year &lt;= 2015,\n    (last_year &gt;= 2015 | is.na(last_year))\n  )\n\ncodes2keep &lt;- fam_type_codes |&gt;\n  filter(survey %in% \"INTERVIEW\") |&gt;\n  select(code_value, code_description)\n\nfam_type_codes &lt;- fam_type_codes |&gt;\n  select(-code_description) |&gt;\n  left_join(codes2keep, by = \"code_value\") |&gt;\n  relocate(code_description, .after = code_value)\n\nfam_type_codes |&gt;\n  filter(code_value %in% c(\"3\", \"5\", \"7\")) |&gt;\n  select(survey, code_value, code_description) |&gt;\n  arrange(code_value, survey) |&gt;\n  kable(booktabs = TRUE)\n\n\n\n\n\n\n\n\n\nsurvey\ncode_value\ncode_description\n\n\n\n\nDIARY\n3\nMarried Couple, own children only oldest child &gt;= 6, &lt;= 17\n\n\nINTERVIEW\n3\nMarried Couple, own children only oldest child &gt;= 6, &lt;= 17\n\n\nDIARY\n5\nAll other Husband and wife families\n\n\nINTERVIEW\n5\nAll other Husband and wife families\n\n\nDIARY\n7\nOne parent, female, own children, at least one age &lt; 18\n\n\nINTERVIEW\n7\nOne parent, female, own children, at least one age &lt; 18\n\n\n\n\n\nNow the codes are consistent across survey instruments and I can use this codebook in my call to ce_prepdata() using the “own_codebook” argument. Then I’ll pass that to ce_mean() per usual.\nNext I’ll get some information about how utilities expenditures are organized using the stub file.\n\ninteg15_hg &lt;- ce_hg(\n  2015,\n  integrated,\n  hg_zip_path = file.path(ce_data_dir, \"stubs.zip\")\n)\n\ninteg15_hg |&gt;\n  filter(str_detect(str_to_lower(title), \"utilities\")) |&gt;\n  kable(bookmarks = TRUE)\n\n\n\n\nlevel\ntitle\nucc\nsurvey\nfactor\n\n\n\n\n3\nUtilities, fuels, and public services\nUTILS\nG\n1\n\n\n\n\n\nThe expenditure category associated with utilities is “Utilities, fuels, and public services”. I’ll store that title to work with later and narrow down the section of the stub file that includes only these expenditures.\n\nutilities_title &lt;- integ15_hg |&gt;\n  filter(str_detect(str_to_lower(title), \"utilities\")) |&gt;\n  pull(title)\n\nutilities_hg &lt;- ce_uccs(\n  integ15_hg,\n  expenditure = utilities_title,\n  uccs_only = FALSE\n)\n\nutilities_hg |&gt; kable(booktabs = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nlevel\ntitle\nucc\nsurvey\nfactor\n\n\n\n\n3\nUtilities, fuels, and public services\nUTILS\nG\n1\n\n\n4\nNatural gas\nNATRLG\nG\n1\n\n\n5\nUtility-natural gas (renter)\n260211\nI\n1\n\n\n5\nUtility-natural gas (owned home)\n260212\nI\n1\n\n\n5\nUtility-natural gas (owned vacation)\n260213\nI\n1\n\n\n5\nUtility-natural gas (rented vacation)\n260214\nI\n1\n\n\n4\nElectricity\nELECTR\nG\n1\n\n\n5\nElectricity (renter)\n260111\nI\n1\n\n\n5\nElectricity (owned home)\n260112\nI\n1\n\n\n5\nElectricity (owned vacation)\n260113\nI\n1\n\n\n5\nElectricity (rented vacation)\n260114\nI\n1\n\n\n4\nFuel oil and other fuels\nOTHRFU\nG\n1\n\n\n5\nFuel oil\nFUELOI\nG\n1\n\n\n6\nFuel oil (renter)\n250111\nI\n1\n\n\n6\nFuel oil (owned home)\n250112\nI\n1\n\n\n6\nFuel oil (owned vacation)\n250113\nI\n1\n\n\n6\nFuel oil (rented vacation)\n250114\nI\n1\n\n\n5\nCoal, wood, and other fuels\nCLWDOT\nG\n1\n\n\n6\nCoal, wood, other fuels (renter)\n250911\nI\n1\n\n\n6\nCoal, wood, other fuels (owned home)\n250912\nI\n1\n\n\n6\nCoal, wood, other fuels (owned vacation)\n250913\nI\n1\n\n\n6\nCoal, wood, other fuels (rented vacation)\n250914\nI\n1\n\n\n5\nBottled gas\nBOTTLG\nG\n1\n\n\n6\nGas, btld/tank (renter)\n250211\nI\n1\n\n\n6\nGas, btld/tank (owned home)\n250212\nI\n1\n\n\n6\nGas, btld/tank (owned vacation)\n250213\nI\n1\n\n\n6\nGas, btld/tank (rented vacation)\n250214\nI\n1\n\n\n4\nTelephone services\nPHONE\nG\n1\n\n\n5\nResidential phone service, VOIP, and phone cards\nRESPHO\nG\n1\n\n\n6\nPhone cards\n270104\nI\n1\n\n\n6\nResidential telephone including VOIP\n270106\nI\n1\n\n\n5\nCellular phone service\n270102\nI\n1\n\n\n4\nWater and other public services\nWATER\nG\n1\n\n\n5\nWater and sewerage maintenance\nSEWER\nG\n1\n\n\n6\nWater/sewer maint. (renter)\n270211\nI\n1\n\n\n6\nWater/sewer maint. (owned home)\n270212\nI\n1\n\n\n6\nWater/sewer maint. (owned vacation)\n270213\nI\n1\n\n\n6\nWater/sewer maint. (rented vacation)\n270214\nI\n1\n\n\n5\nTrash and garbage collection\nTRASH\nG\n1\n\n\n6\nTrash/garb. coll. (renter)\n270411\nI\n1\n\n\n6\nTrash/garb. coll. (owned home)\n270412\nI\n1\n\n\n6\nTrash/garb. coll. (owned vacation)\n270413\nI\n1\n\n\n6\nTrash/garb. coll. (rented vacation)\n270414\nI\n1\n\n\n5\nSeptic tank cleaning\nSEPTAN\nG\n1\n\n\n6\nSeptic tank clean. (renter)\n270901\nI\n1\n\n\n6\nSeptic tank clean. (owned home)\n270902\nI\n1\n\n\n6\nSeptic tank clean. (owned vacation)\n270903\nI\n1\n\n\n6\nSeptic tank clean. (rented vacation)\n270904\nI\n1\n\n\n\n\n\nI also want to know what survey instruments the expenditures are collected through for published estimates. My stub file is the integrated stub file, so I should see both “I” and “D” in the survey colum of the stub file if expenditures are collected through both instruments.\n\nutilities_hg |&gt; distinct(survey) |&gt; kable(booktabs = TRUE)\n\n\n\n\nsurvey\n\n\n\n\nG\n\n\nI\n\n\n\n\n\nIt seems utlities expenditures are collected only through the Interview survey, so I’ll only need to use Interview data files to calculate estimates.\n\nfam_type_utilities &lt;- ce_prepdata(\n  2015,\n  interview,\n  utilities_hg,\n  uccs = ce_uccs(utilities_hg, expenditure = utilities_title),\n  fam_type, \n  int_zp = file.path(ce_data_dir, \"intrvw15.zip\"),\n  recode_variables = TRUE,\n  dict_path = file.path(ce_data_dir, \"ce-data-dict.xlsx\")\n) |&gt;\n  group_nest(fam_type) |&gt;\n  mutate(ce_mean_df = map(data, ce_mean)) |&gt;\n  select(-data) |&gt;\n  unnest(ce_mean_df)\n\nfam_type_utilities |&gt;\n  arrange(fam_type) |&gt;\n  kable(booktabs = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nfam_type\nagg_exp\nmean_exp\nse\ncv\n\n\n\n\nMarried Couple only\n122623482952\n4378.377\n76.25699\n1.741673\n\n\nMarried Couple, own children only, oldest child &lt; 6\n21592090354\n4073.529\n241.48233\n5.928087\n\n\nMarried Couple, own children only oldest child &gt;= 6, &lt;= 17\n73899626502\n5136.781\n132.53306\n2.580080\n\n\nMarried Couple, own children only, oldest child &gt; 17\n53687574363\n5585.027\n190.15164\n3.404668\n\n\nAll other Husband and wife families\n26767356778\n5699.177\n331.83382\n5.822487\n\n\nOne parent, male, own children at least one age &lt; 18\n4647315390\n3887.863\n532.21229\n13.689069\n\n\nOne parent, female, own children, at least one age &lt; 18\n22862016917\n3684.480\n237.12762\n6.435851\n\n\nSingle consumers\n88002147354\n2348.182\n40.59815\n1.728919\n\n\nOther families\n84986387660\n3942.345\n122.97865\n3.119429\n\n\n\n\n\nAnd finally, a quick lollipop plot.\n\nfam_type_utilities |&gt;\n  mutate(fam_type = fct_reorder(fam_type, mean_exp)) |&gt;\n  ggplot(aes(x = mean_exp, y = fam_type, mean_exp)) +\n  geom_segment(aes(x = 0, xend = mean_exp, yend = fam_type)) +\n  geom_point(color = \"red\", size = 5) +\n  scale_y_discrete(labels = function(x) str_wrap(x, width = 25)) +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(\n    y = \"CU composition (FAM_TYPE)\",\n    x = \"Estimated, weighted, annual mean expenditure\",\n    title =\n      \"Estimated annual mean utilities expenditures by CU composition\"\n  ) +\n  theme_bw()"
  },
  {
    "objectID": "cepumd-intro.html#conclusion",
    "href": "cepumd-intro.html#conclusion",
    "title": "Introduction to cepumd",
    "section": "Conclusion",
    "text": "Conclusion\nThat wraps up this introduction to cepumd. Thank you for taking a look. If you find any bugs, please report them on the Github repo issues section."
  }
]